{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45d66fc1",
   "metadata": {},
   "source": [
    "## Pre-lecture HW "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df81149",
   "metadata": {},
   "source": [
    "### ChatGPT Summary\n",
    "\n",
    "Funny Interesting Datasets - https://chatgpt.com/share/d21d5a31-8756-4d55-9137-01fa3578806b\n",
    "\n",
    "\n",
    "Dataset Rows and Columns - https://chatgpt.com/share/ec705962-684e-40db-8a79-e4d3f9c2bc03\n",
    "\n",
    "\n",
    "Attribute vs Method - https://chatgpt.com/share/b6200e9c-b1da-49b6-89c8-23317f013f70\n",
    "\n",
    "\n",
    "Dataset Analysis Python Code - https://chatgpt.com/share/911944af-b43e-455f-b1b8-2c339ba09e72\n",
    "\n",
    "\n",
    "\n",
    "Hereâ€™s a summary of our previous interactions based on the exchanges you provided:\n",
    "\n",
    "Exchange 1: Checking for Missing Values in a CSV Dataset\n",
    "\n",
    "    You shared a CSV dataset link, and I provided Python code to check for missing values in the dataset using pandas. The code reads the CSV file from the URL and uses isnull().sum() to calculate missing values in each column.\n",
    "\n",
    "Exchange 2: Counting Rows and Columns\n",
    "\n",
    "    You asked how to count rows and columns in the dataset using Python. I explained that by using pandas, you could load the dataset and check the dimensions with df.shape, which returns the number of rows and columns as a tuple.\n",
    "    You also asked for clarification on the terms \"observations\" and \"variables.\" I explained that observations correspond to rows in the dataset (individual villagers), and variables correspond to columns (characteristics of the villagers).\n",
    "\n",
    "Exchange 3: Summarizing Columns in a Dataset\n",
    "\n",
    "    You asked how to generate summaries of the dataset's columns. I provided Python code that uses info(), describe(), and value_counts() to display information about numeric and non-numeric columns. These methods give overviews like data types, summary statistics, and the frequency of unique values in specific columns.\n",
    "\n",
    "Exchange 4: Titanic Dataset Summary\n",
    "\n",
    "    You requested an example using a Titanic dataset. I provided code to load the Titanic dataset, obtain its shape using df.shape, and generate summary statistics with df.describe().\n",
    "\n",
    "Exchange 5: Attributes vs Methods\n",
    "\n",
    "    You asked about the difference between an attribute (like df.shape) and a method (like df.describe()). I explained that an attribute stores a value or property of the object and doesn't require parentheses, while a method is a function that performs an action and is invoked with parentheses, optionally containing arguments.\n",
    "\n",
    "This summary captures the key details of our previous exchanges. Let me know if you need further details or adjustments!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae42171",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "611e9d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the CSV file\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "\n",
    "# Reading the CSV file\n",
    "villagers_df = pd.read_csv(url)\n",
    "\n",
    "# Checking for missing values\n",
    "missing_values = villagers_df.isnull().sum()\n",
    "\n",
    "# Output the missing values\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a0e02",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ffc3cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 391, Columns: 11\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_data = pd.read_csv(url)\n",
    "\n",
    "# Get the number of rows and columns\n",
    "num_rows, num_columns = villagers_data.shape\n",
    "print(f'Rows: {num_rows}, Columns: {num_columns}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edde044f",
   "metadata": {},
   "source": [
    "#### Definitions\n",
    "Observations - Individual datapoints, usually represented as rows in a dataset.\n",
    "\n",
    "Variables - Specific attributes or characteristics measured for each observation, usually represented as columns in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0510cbe7",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b9c5e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Info of the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 391 entries, 0 to 390\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   row_n        391 non-null    int64 \n",
      " 1   id           390 non-null    object\n",
      " 2   name         391 non-null    object\n",
      " 3   gender       391 non-null    object\n",
      " 4   species      391 non-null    object\n",
      " 5   birthday     391 non-null    object\n",
      " 6   personality  391 non-null    object\n",
      " 7   song         380 non-null    object\n",
      " 8   phrase       391 non-null    object\n",
      " 9   full_id      391 non-null    object\n",
      " 10  url          391 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 33.7+ KB\n",
      "\n",
      "Summary statistics for numeric columns:\n",
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n",
      "\n",
      "Summary statistics for categorical columns:\n",
      "             id     name gender species birthday personality          song  \\\n",
      "count       390      391    391     391      391         391           380   \n",
      "unique      390      391      2      35      361           8            92   \n",
      "top     admiral  Admiral   male     cat     1-27        lazy  K.K. Country   \n",
      "freq          1        1    204      23        2          60            10   \n",
      "\n",
      "         phrase           full_id  \\\n",
      "count       391               391   \n",
      "unique      388               391   \n",
      "top     wee one  villager-admiral   \n",
      "freq          2                 1   \n",
      "\n",
      "                                                      url  \n",
      "count                                                 391  \n",
      "unique                                                391  \n",
      "top     https://villagerdb.com/images/villagers/thumb/...  \n",
      "freq                                                    1  \n",
      "\n",
      "Value counts for 'species' column:\n",
      "species\n",
      "cat          23\n",
      "rabbit       20\n",
      "frog         18\n",
      "squirrel     18\n",
      "duck         17\n",
      "dog          16\n",
      "cub          16\n",
      "pig          15\n",
      "bear         15\n",
      "mouse        15\n",
      "horse        15\n",
      "bird         13\n",
      "penguin      13\n",
      "sheep        13\n",
      "elephant     11\n",
      "wolf         11\n",
      "ostrich      10\n",
      "deer         10\n",
      "eagle         9\n",
      "gorilla       9\n",
      "chicken       9\n",
      "koala         9\n",
      "goat          8\n",
      "hamster       8\n",
      "kangaroo      8\n",
      "monkey        8\n",
      "anteater      7\n",
      "hippo         7\n",
      "tiger         7\n",
      "alligator     7\n",
      "lion          7\n",
      "bull          6\n",
      "rhino         6\n",
      "cow           4\n",
      "octopus       3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_data = pd.read_csv(url)\n",
    "\n",
    "# Summary of the dataset\n",
    "print(\"Basic Info of the dataset:\")\n",
    "villagers_data.info()  # Provides an overview of the columns and data types\n",
    "\n",
    "print(\"\\nSummary statistics for numeric columns:\")\n",
    "print(villagers_data.describe())  # Summary for numeric columns\n",
    "\n",
    "print(\"\\nSummary statistics for categorical columns:\")\n",
    "print(villagers_data.describe(include='object'))  # Summary for non-numeric columns\n",
    "\n",
    "# To show the value counts for a specific column, for example, the 'species' column:\n",
    "print(\"\\nValue counts for 'species' column:\")\n",
    "print(villagers_data['species'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f8ccf",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "008800d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (891, 15)\n",
      "\n",
      "Summary statistics of the dataset:\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the dataset (rows, columns)\n",
    "print(\"Shape of the dataset:\", titanic_data.shape)\n",
    "\n",
    "# Get summary statistics of the dataset\n",
    "print(\"\\nSummary statistics of the dataset:\")\n",
    "print(titanic_data.describe())\n",
    "\n",
    "# Checking for missing values\n",
    "missing_values = titanic_data.isnull().sum()\n",
    "\n",
    "# Output the missing values\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd1bbbf",
   "metadata": {},
   "source": [
    "#### Why the discrepancies?\n",
    "\n",
    "I think there are discrepancies because df.describe() will only analyzes numeric columns and not non-numeric columns. Also if there are missing values in numeric variables, the \"count\" row in df.describe() will show the number of non-missing values for each column. This is be less than the total number of rows reported by df.shape for the titanic data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af98241f",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa1e4a",
   "metadata": {},
   "source": [
    "#### Differences\n",
    "Attribute - A property of an object that contains data and is accessed directly without parentheses. \n",
    "\n",
    "df.shape is an attribute that returns the dimensions of df without performing any computation.\n",
    "\n",
    "____\n",
    "\n",
    "Method - Associated with an object and  performs an action, often using the object's attributes, and is called using parentheses.\n",
    "\n",
    "df.describe() is a method that computes summary statistics of df's columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c9719b",
   "metadata": {},
   "source": [
    "## Post-lecture HW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5ec870",
   "metadata": {},
   "source": [
    "### Chatbot Summary (not ChatGPT)\n",
    "\n",
    "\n",
    "\n",
    "Certainly. Here's a summary of our exchanges:\n",
    "\n",
    "1. We discussed the Titanic dataset and methods for handling missing data in pandas.\n",
    "2. We explored the differences between df.dropna() and del df['col'] for removing missing data, including use cases for each method and the importance of their order of application.\n",
    "3. We created a code snippet demonstrating the process of cleaning the Titanic dataset by removing a column with many missing values ('deck') and then dropping rows with remaining missing data.\n",
    "4. We discussed the df.groupby(\"col1\")[\"col2\"].describe() function, explaining its purpose and how it differs from df.describe().\n",
    "5. Throughout our discussion, we emphasized the importance of understanding how these methods affect data retention and the insights they can provide in exploratory data analysis.\n",
    "6. We used the Titanic dataset as a concrete example to illustrate these concepts, discussing how grouping by passenger class and examining age distribution could reveal patterns in the data.\n",
    "\n",
    "This summary covers the key points of our conversation, demonstrating your engagement with the concepts of data cleaning, handling missing values, and using pandas functions for exploratory data analysis. It shows your progress in understanding these important data science techniques and your ability to apply them to real-world datasets like the Titanic data.\n",
    "\n",
    "\n",
    "--\n",
    "\n",
    "Sure! Hereâ€™s a summary of our exchanges:\n",
    "\n",
    "Error Fixes and Code Corrections:\n",
    "- NameError: name 'pd' is not defined: This issue was resolved by ensuring that pandas is imported with the alias pd using import pandas as pd.\n",
    "- HTTPError: HTTP Error 404: Not Found: This was fixed by correcting the URL for loading the Titanic dataset from https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titasnic.csv to https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv.\n",
    "- SyntaxError: incomplete input: The error was corrected by ensuring the describe() method call had a proper closing parenthesis and that the print() statement was properly placed.\n",
    "- NameError: name 'original_titanic_data_not_cleaned' is not defined: This was resolved by ensuring the DataFrame was defined and loaded before performing operations on it.\n",
    "- KeyError: 'Survived': The issue was fixed by checking the DataFrame's actual column names and ensuring the correct column name (likely 'survived') was used.\n",
    "- AttributeError: module 'pandas' has no attribute 'readcsv': This was corrected by using the proper method pd.read_csv() instead of the incorrect pd.readcsv().\n",
    "\n",
    "Additional Help:\n",
    "- Provided guidance on ensuring correct column names for grouping operations and correct syntax for reading CSV files using pandas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cf604d",
   "metadata": {},
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce96ccb1",
   "metadata": {},
   "source": [
    "### Summary Statistics\n",
    "\n",
    "Count - This is the number of datapoints in the column\n",
    "\n",
    "Mean - This is the average (sum of total values divided by count)\n",
    "\n",
    "STD (Standard Deviation) - This is the amount of variation in the dataset. This means how far or spread out the data is from the mean\n",
    "\n",
    "Min - The minimum value in each column\n",
    "\n",
    "25% - 25% of the data falls below this value\n",
    "\n",
    "50% - 50% of the data falls below this value\n",
    "\n",
    "75% - 75% of the data falls below this value\n",
    "\n",
    "Max - The maximum value in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a52e0",
   "metadata": {},
   "source": [
    "### 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92386702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     891 non-null    int64  \n",
      " 1   pclass       891 non-null    int64  \n",
      " 2   sex          891 non-null    object \n",
      " 3   age          714 non-null    float64\n",
      " 4   sibsp        891 non-null    int64  \n",
      " 5   parch        891 non-null    int64  \n",
      " 6   fare         891 non-null    float64\n",
      " 7   embarked     889 non-null    object \n",
      " 8   class        891 non-null    object \n",
      " 9   who          891 non-null    object \n",
      " 10  adult_male   891 non-null    bool   \n",
      " 11  deck         203 non-null    object \n",
      " 12  embark_town  889 non-null    object \n",
      " 13  alive        891 non-null    object \n",
      " 14  alone        891 non-null    bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(7)\n",
      "memory usage: 92.4+ KB\n",
      "None\n",
      "\n",
      "Missing values per column:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Display initial information about the dataset\n",
    "print(titanic_data.info())\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(titanic_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc29bc73",
   "metadata": {},
   "source": [
    "#### 1.\n",
    "\n",
    "Use case for df.dropna():\n",
    "A use case for preferring df.dropna() could be when you need to have complete data so you drop any rows that are missing data. This makes sure that every row and column are complete for all variables.\n",
    "\n",
    "#### 2.\n",
    "\n",
    "Use case for del df['col']:\n",
    "A use case for preferring del df['col'] could be when a specific column has a high percentage of missing values and isn't crucial for your analysis. For example, the 'deck' column in the Titanic dataset has many missing values and I don't consider it essential for some analysis or model that I am creating. I could delete this column entirely rather than losing a large portion of the dataset by dropping incomplete rows.\n",
    "#### 3.\n",
    "\n",
    "The importance of using df['col'] before df.dropna(), is that if you are planning to delete a column, but you delete all the 'incomplete' rows first, those rows might have only been incomplete because of the column you were planning to drop. By removing columns with many missing values first, you reduce the number of rows that will be dropped due to missing data in the remaining columns. This helps maximize data retention.\n",
    "\n",
    "#### 4.\n",
    "\n",
    "Code below which satisfies the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ca4725a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     891 non-null    int64  \n",
      " 1   pclass       891 non-null    int64  \n",
      " 2   sex          891 non-null    object \n",
      " 3   age          714 non-null    float64\n",
      " 4   sibsp        891 non-null    int64  \n",
      " 5   parch        891 non-null    int64  \n",
      " 6   fare         891 non-null    float64\n",
      " 7   embarked     889 non-null    object \n",
      " 8   class        891 non-null    object \n",
      " 9   who          891 non-null    object \n",
      " 10  adult_male   891 non-null    bool   \n",
      " 11  deck         203 non-null    object \n",
      " 12  embark_town  889 non-null    object \n",
      " 13  alive        891 non-null    object \n",
      " 14  alone        891 non-null    bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(7)\n",
      "memory usage: 92.4+ KB\n",
      "None\n",
      "\n",
      "Cleaned dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 712 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     712 non-null    int64  \n",
      " 1   pclass       712 non-null    int64  \n",
      " 2   sex          712 non-null    object \n",
      " 3   age          712 non-null    float64\n",
      " 4   sibsp        712 non-null    int64  \n",
      " 5   parch        712 non-null    int64  \n",
      " 6   fare         712 non-null    float64\n",
      " 7   embarked     712 non-null    object \n",
      " 8   class        712 non-null    object \n",
      " 9   who          712 non-null    object \n",
      " 10  adult_male   712 non-null    bool   \n",
      " 11  embark_town  712 non-null    object \n",
      " 12  alive        712 non-null    object \n",
      " 13  alone        712 non-null    bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(6)\n",
      "memory usage: 73.7+ KB\n",
      "None\n",
      "\n",
      "Percentage of data retained: 79.91%\n"
     ]
    }
   ],
   "source": [
    "# Original dataset info\n",
    "print(\"Original dataset:\")\n",
    "print(titanic_data.info())\n",
    "\n",
    "# Remove 'deck' column due to high missing values\n",
    "del titanic_data['deck']\n",
    "\n",
    "# Drop rows with missing values in remaining columns\n",
    "titanic_data_clean = titanic_data.dropna()\n",
    "\n",
    "# After cleaning dataset info\n",
    "print(\"\\nCleaned dataset:\")\n",
    "print(titanic_data_clean.info())\n",
    "\n",
    "# Calculate percentage of data retained\n",
    "retention_rate = (len(titanic_data_clean) / len(titanic_data)) * 100\n",
    "print(f\"\\nPercentage of data retained: {retention_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3766f4",
   "metadata": {},
   "source": [
    "### 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f558168c",
   "metadata": {},
   "source": [
    "#### 1.\n",
    "\n",
    "The code 'df.groupby(\"col1\")[\"col2\"].describe()' is demonstrated below. This groups data in 'col1' into groups based on having the same values. Then summary statistics are calculated using the groups 'col1' but using 'col2' data to get summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452a235b",
   "metadata": {},
   "source": [
    "#### Code below is by AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "943a3e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std   min   25%   50%   75%   max\n",
      "pclass                                                           \n",
      "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
      "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
      "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0\n"
     ]
    }
   ],
   "source": [
    "original_titanic_data_not_cleaned = pd.read_csv(url)\n",
    "result = original_titanic_data_not_cleaned.groupby(\"pclass\")[\"age\"].describe()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d007b276",
   "metadata": {},
   "source": [
    "#### Code below is written by me (Gabriel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c55002a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          count       mean        std  min      25%   50%   75%       max\n",
      "survived                                                                 \n",
      "0         549.0  22.117887  31.388207  0.0   7.8542  10.5  26.0  263.0000\n",
      "1         342.0  48.395408  66.596998  0.0  12.4750  26.0  57.0  512.3292\n"
     ]
    }
   ],
   "source": [
    "results_me = original_titanic_data_not_cleaned.groupby('survived')['fare'].describe()\n",
    "print(results_me)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8ce87d",
   "metadata": {},
   "source": [
    "#### 2.\n",
    "\n",
    "##### What is df.describe() doing?\n",
    "The count here represents the number of non-null or non-missing values in each column. It depicts the presence of missing values in each column independently.\n",
    "\n",
    "##### What is df.groupby(\"col1\")[\"col2\"].describe() doing?\n",
    "The count here represents the number of non-null values of \"col2\" for each unique value in \"col1\". This is fundamentally different because:\n",
    "\n",
    "1. It is showing the distribution of data across groups defined by \"col1\".\n",
    "2. It allows us to compare the presence and characteristics of \"col2\" data across different groups in \"col1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82715e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "print(original_titanic_data_not_cleaned.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b599d02",
   "metadata": {},
   "source": [
    "#### 3.\n",
    "\n",
    "\n",
    "I think that ChatGPT is better overall. This is because it does an excellent job tailoring solutions for my needs. Sometimes, searching Google is faster if it was a really complex issue which someone else has documented. I found a website called StackOverflow through Google which gave insightful results.\n",
    "\n",
    "ChatGPT only works well if given the code where the issue is caused. For example, if there is a missing bracket, showing ChatGPT the error is not enough to get a proper fix.\n",
    "\n",
    "For G., ChatGPT was more helpful as it recognized the error. I found Google was unhelpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1044cc",
   "metadata": {},
   "source": [
    "### 9\n",
    "\n",
    "Yes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
