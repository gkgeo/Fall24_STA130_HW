{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de471209",
   "metadata": {},
   "source": [
    "## Pre-lecture HW "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0c05bc",
   "metadata": {},
   "source": [
    "### ChatGPT Summary\n",
    "\n",
    "Funny Interesting Datasets - https://chatgpt.com/share/d21d5a31-8756-4d55-9137-01fa3578806b\n",
    "\n",
    "\n",
    "Dataset Rows and Columns - https://chatgpt.com/share/ec705962-684e-40db-8a79-e4d3f9c2bc03\n",
    "\n",
    "\n",
    "Attribute vs Method - https://chatgpt.com/share/b6200e9c-b1da-49b6-89c8-23317f013f70\n",
    "\n",
    "\n",
    "Dataset Analysis Python Code - https://chatgpt.com/share/911944af-b43e-455f-b1b8-2c339ba09e72\n",
    "\n",
    "\n",
    "\n",
    "Hereâ€™s a summary of our previous interactions based on the exchanges you provided:\n",
    "\n",
    "Exchange 1: Checking for Missing Values in a CSV Dataset\n",
    "\n",
    "    You shared a CSV dataset link, and I provided Python code to check for missing values in the dataset using pandas. The code reads the CSV file from the URL and uses isnull().sum() to calculate missing values in each column.\n",
    "\n",
    "Exchange 2: Counting Rows and Columns\n",
    "\n",
    "    You asked how to count rows and columns in the dataset using Python. I explained that by using pandas, you could load the dataset and check the dimensions with df.shape, which returns the number of rows and columns as a tuple.\n",
    "    You also asked for clarification on the terms \"observations\" and \"variables.\" I explained that observations correspond to rows in the dataset (individual villagers), and variables correspond to columns (characteristics of the villagers).\n",
    "\n",
    "Exchange 3: Summarizing Columns in a Dataset\n",
    "\n",
    "    You asked how to generate summaries of the dataset's columns. I provided Python code that uses info(), describe(), and value_counts() to display information about numeric and non-numeric columns. These methods give overviews like data types, summary statistics, and the frequency of unique values in specific columns.\n",
    "\n",
    "Exchange 4: Titanic Dataset Summary\n",
    "\n",
    "    You requested an example using a Titanic dataset. I provided code to load the Titanic dataset, obtain its shape using df.shape, and generate summary statistics with df.describe().\n",
    "\n",
    "Exchange 5: Attributes vs Methods\n",
    "\n",
    "    You asked about the difference between an attribute (like df.shape) and a method (like df.describe()). I explained that an attribute stores a value or property of the object and doesn't require parentheses, while a method is a function that performs an action and is invoked with parentheses, optionally containing arguments.\n",
    "\n",
    "This summary captures the key details of our previous exchanges. Let me know if you need further details or adjustments!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef138c3",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f618f962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the CSV file\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "\n",
    "# Reading the CSV file\n",
    "villagers_df = pd.read_csv(url)\n",
    "\n",
    "# Checking for missing values\n",
    "missing_values = villagers_df.isnull().sum()\n",
    "\n",
    "# Output the missing values\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f370b3",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd7bb063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 391, Columns: 11\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_data = pd.read_csv(url)\n",
    "\n",
    "# Get the number of rows and columns\n",
    "num_rows, num_columns = villagers_data.shape\n",
    "print(f'Rows: {num_rows}, Columns: {num_columns}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30986124",
   "metadata": {},
   "source": [
    "#### Definitions\n",
    "Observations - Individual datapoints in a dataset, usually represented as rows. Each observation is a single instance or unit of data collection.\n",
    "\n",
    "\n",
    "Variables - Specific attributes or characteristics measured for each observation, usually represented as columns in a dataset. Variables can be quantitative (numeric) or qualitative (categorical). Example: personality, song, phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51728d71",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44a802d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Info of the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 391 entries, 0 to 390\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   row_n        391 non-null    int64 \n",
      " 1   id           390 non-null    object\n",
      " 2   name         391 non-null    object\n",
      " 3   gender       391 non-null    object\n",
      " 4   species      391 non-null    object\n",
      " 5   birthday     391 non-null    object\n",
      " 6   personality  391 non-null    object\n",
      " 7   song         380 non-null    object\n",
      " 8   phrase       391 non-null    object\n",
      " 9   full_id      391 non-null    object\n",
      " 10  url          391 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 33.7+ KB\n",
      "\n",
      "Summary statistics for numeric columns:\n",
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n",
      "\n",
      "Summary statistics for categorical columns:\n",
      "             id     name gender species birthday personality          song  \\\n",
      "count       390      391    391     391      391         391           380   \n",
      "unique      390      391      2      35      361           8            92   \n",
      "top     admiral  Admiral   male     cat     1-27        lazy  K.K. Country   \n",
      "freq          1        1    204      23        2          60            10   \n",
      "\n",
      "         phrase           full_id  \\\n",
      "count       391               391   \n",
      "unique      388               391   \n",
      "top     wee one  villager-admiral   \n",
      "freq          2                 1   \n",
      "\n",
      "                                                      url  \n",
      "count                                                 391  \n",
      "unique                                                391  \n",
      "top     https://villagerdb.com/images/villagers/thumb/...  \n",
      "freq                                                    1  \n",
      "\n",
      "Value counts for 'species' column:\n",
      "species\n",
      "cat          23\n",
      "rabbit       20\n",
      "frog         18\n",
      "squirrel     18\n",
      "duck         17\n",
      "dog          16\n",
      "cub          16\n",
      "pig          15\n",
      "bear         15\n",
      "mouse        15\n",
      "horse        15\n",
      "bird         13\n",
      "penguin      13\n",
      "sheep        13\n",
      "elephant     11\n",
      "wolf         11\n",
      "ostrich      10\n",
      "deer         10\n",
      "eagle         9\n",
      "gorilla       9\n",
      "chicken       9\n",
      "koala         9\n",
      "goat          8\n",
      "hamster       8\n",
      "kangaroo      8\n",
      "monkey        8\n",
      "anteater      7\n",
      "hippo         7\n",
      "tiger         7\n",
      "alligator     7\n",
      "lion          7\n",
      "bull          6\n",
      "rhino         6\n",
      "cow           4\n",
      "octopus       3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_data = pd.read_csv(url)\n",
    "\n",
    "# Summary of the dataset\n",
    "print(\"Basic Info of the dataset:\")\n",
    "villagers_data.info()  # Provides an overview of the columns and data types\n",
    "\n",
    "print(\"\\nSummary statistics for numeric columns:\")\n",
    "print(villagers_data.describe())  # Summary for numeric columns\n",
    "\n",
    "print(\"\\nSummary statistics for categorical columns:\")\n",
    "print(villagers_data.describe(include='object'))  # Summary for non-numeric columns\n",
    "\n",
    "# To show the value counts for a specific column, for example, the 'species' column:\n",
    "print(\"\\nValue counts for 'species' column:\")\n",
    "print(villagers_data['species'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758d58d6",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4acf780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (891, 15)\n",
      "\n",
      "Summary statistics of the dataset:\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the dataset (rows, columns)\n",
    "print(\"Shape of the dataset:\", titanic_data.shape)\n",
    "\n",
    "# Get summary statistics of the dataset\n",
    "print(\"\\nSummary statistics of the dataset:\")\n",
    "print(titanic_data.describe())\n",
    "\n",
    "# Checking for missing values\n",
    "missing_values = titanic_data.isnull().sum()\n",
    "\n",
    "# Output the missing values\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da913194",
   "metadata": {},
   "source": [
    "#### Why the discrepancies?\n",
    "\n",
    "I think there are discrepancies because df.describe() will only analyze numeric columns and not non-numeric columns. Also if there are missing values in numeric variables, the \"count\" row in df.describe() will show the number of non-missing values for each column. This will be less than the total number of rows reported by df.shape for the titanic data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e3f402",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e08e831",
   "metadata": {},
   "source": [
    "#### Differences\n",
    "Attribute - A property of an object that contains data and is accessed directly without parentheses. \n",
    "\n",
    "df.shape is an attribute that returns the dimensions of df without performing any computation.\n",
    "\n",
    "____\n",
    "\n",
    "Method - Associated with an object and  performs an action or calculation, often using the object's attributes, and is called using parentheses.\n",
    "\n",
    "df.describe() is a method that computes summary statistics of df's columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f72c3d7",
   "metadata": {},
   "source": [
    "## Post-lecture HW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b274bc4",
   "metadata": {},
   "source": [
    "### Chatbot Summary (not ChatGPT)\n",
    "\n",
    "\n",
    "\n",
    "Certainly. Here's a summary of our exchanges:\n",
    "\n",
    "1. We discussed the Titanic dataset and methods for handling missing data in pandas.\n",
    "2. We explored the differences between df.dropna() and del df['col'] for removing missing data, including use cases for each method and the importance of their order of application.\n",
    "3. We created a code snippet demonstrating the process of cleaning the Titanic dataset by removing a column with many missing values ('deck') and then dropping rows with remaining missing data.\n",
    "4. We discussed the df.groupby(\"col1\")[\"col2\"].describe() function, explaining its purpose and how it differs from df.describe().\n",
    "5. Throughout our discussion, we emphasized the importance of understanding how these methods affect data retention and the insights they can provide in exploratory data analysis.\n",
    "6. We used the Titanic dataset as a concrete example to illustrate these concepts, discussing how grouping by passenger class and examining age distribution could reveal patterns in the data.\n",
    "\n",
    "This summary covers the key points of our conversation, demonstrating your engagement with the concepts of data cleaning, handling missing values, and using pandas functions for exploratory data analysis. It shows your progress in understanding these important data science techniques and your ability to apply them to real-world datasets like the Titanic data.\n",
    "\n",
    "\n",
    "--\n",
    "\n",
    "Sure! Hereâ€™s a summary of our exchanges:\n",
    "\n",
    "Error Fixes and Code Corrections:\n",
    "- NameError: name 'pd' is not defined: This issue was resolved by ensuring that pandas is imported with the alias pd using import pandas as pd.\n",
    "- HTTPError: HTTP Error 404: Not Found: This was fixed by correcting the URL for loading the Titanic dataset from https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titasnic.csv to https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv.\n",
    "- SyntaxError: incomplete input: The error was corrected by ensuring the describe() method call had a proper closing parenthesis and that the print() statement was properly placed.\n",
    "- NameError: name 'original_titanic_data_not_cleaned' is not defined: This was resolved by ensuring the DataFrame was defined and loaded before performing operations on it.\n",
    "- KeyError: 'Survived': The issue was fixed by checking the DataFrame's actual column names and ensuring the correct column name (likely 'survived') was used.\n",
    "- AttributeError: module 'pandas' has no attribute 'readcsv': This was corrected by using the proper method pd.read_csv() instead of the incorrect pd.readcsv().\n",
    "\n",
    "Additional Help:\n",
    "- Provided guidance on ensuring correct column names for grouping operations and correct syntax for reading CSV files using pandas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fcf808",
   "metadata": {},
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979c5d47",
   "metadata": {},
   "source": [
    "### Summary Statistics\n",
    "\n",
    "Count - This is the number of datapoints in the column\n",
    "\n",
    "Mean - This is the average (sum of total values divided by count)\n",
    "\n",
    "STD (Standard Deviation) - This is the amount of variation in the dataset. This means how far or spread out the data is from the mean\n",
    "\n",
    "Min - The minimum value in each column\n",
    "\n",
    "25% - 25% of the data falls below this value\n",
    "\n",
    "50% - 50% of the data falls below this value\n",
    "\n",
    "75% - 75% of the data falls below this value\n",
    "\n",
    "Max - The maximum value in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a1bb59",
   "metadata": {},
   "source": [
    "### 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c26b8b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     891 non-null    int64  \n",
      " 1   pclass       891 non-null    int64  \n",
      " 2   sex          891 non-null    object \n",
      " 3   age          714 non-null    float64\n",
      " 4   sibsp        891 non-null    int64  \n",
      " 5   parch        891 non-null    int64  \n",
      " 6   fare         891 non-null    float64\n",
      " 7   embarked     889 non-null    object \n",
      " 8   class        891 non-null    object \n",
      " 9   who          891 non-null    object \n",
      " 10  adult_male   891 non-null    bool   \n",
      " 11  deck         203 non-null    object \n",
      " 12  embark_town  889 non-null    object \n",
      " 13  alive        891 non-null    object \n",
      " 14  alone        891 non-null    bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(7)\n",
      "memory usage: 92.4+ KB\n",
      "None\n",
      "\n",
      "Missing values per column:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Display initial information about the dataset\n",
    "print(titanic_data.info())\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(titanic_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d1e9b",
   "metadata": {},
   "source": [
    "#### 1.\n",
    "\n",
    "Use case for df.dropna():\n",
    "A use case for preferring df.dropna() could be when you need to have complete data so you drop any rows that are missing data. This makes sure that every row and column are complete for all variables.\n",
    "\n",
    "#### 2.\n",
    "\n",
    "Use case for del df['col']:\n",
    "A use case for preferring del df['col'] could be when a specific column has a high percentage of missing values and isn't crucial for your analysis. For example, the 'deck' column in the Titanic dataset has many missing values and I don't consider it essential for some analysis or model that I am creating. I could delete this column entirely rather than losing a large portion of the dataset by dropping incomplete rows.\n",
    "#### 3.\n",
    "\n",
    "The importance of using df['col'] before df.dropna(), is that if you are planning to delete a column, but you delete all the 'incomplete' rows first, those rows might have only been incomplete because of the column you were planning to drop. By removing columns with many missing values first, you reduce the number of rows that will be dropped due to missing data in the remaining columns. This helps maximize data retention. For example, for the titanic dataset, if you remove the embark_town column you will lose a lot of good data, while removing the column would be more benificial.\n",
    "\n",
    "#### 4.\n",
    "\n",
    "Code below which satisfies the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16ab7e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     891 non-null    int64  \n",
      " 1   pclass       891 non-null    int64  \n",
      " 2   sex          891 non-null    object \n",
      " 3   age          714 non-null    float64\n",
      " 4   sibsp        891 non-null    int64  \n",
      " 5   parch        891 non-null    int64  \n",
      " 6   fare         891 non-null    float64\n",
      " 7   embarked     889 non-null    object \n",
      " 8   class        891 non-null    object \n",
      " 9   who          891 non-null    object \n",
      " 10  adult_male   891 non-null    bool   \n",
      " 11  deck         203 non-null    object \n",
      " 12  embark_town  889 non-null    object \n",
      " 13  alive        891 non-null    object \n",
      " 14  alone        891 non-null    bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(7)\n",
      "memory usage: 92.4+ KB\n",
      "None\n",
      "\n",
      "Cleaned dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 712 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     712 non-null    int64  \n",
      " 1   pclass       712 non-null    int64  \n",
      " 2   sex          712 non-null    object \n",
      " 3   age          712 non-null    float64\n",
      " 4   sibsp        712 non-null    int64  \n",
      " 5   parch        712 non-null    int64  \n",
      " 6   fare         712 non-null    float64\n",
      " 7   embarked     712 non-null    object \n",
      " 8   class        712 non-null    object \n",
      " 9   who          712 non-null    object \n",
      " 10  adult_male   712 non-null    bool   \n",
      " 11  embark_town  712 non-null    object \n",
      " 12  alive        712 non-null    object \n",
      " 13  alone        712 non-null    bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(6)\n",
      "memory usage: 73.7+ KB\n",
      "None\n",
      "\n",
      "Percentage of data retained: 79.91%\n"
     ]
    }
   ],
   "source": [
    "# Original dataset info\n",
    "print(\"Original dataset:\")\n",
    "print(titanic_data.info())\n",
    "\n",
    "# Remove 'deck' column due to high missing values\n",
    "del titanic_data['deck']\n",
    "\n",
    "# Drop rows with missing values in remaining columns\n",
    "titanic_data_clean = titanic_data.dropna()\n",
    "\n",
    "# After cleaning dataset info\n",
    "print(\"\\nCleaned dataset:\")\n",
    "print(titanic_data_clean.info())\n",
    "\n",
    "# Calculate percentage of data retained\n",
    "retention_rate = (len(titanic_data_clean) / len(titanic_data)) * 100\n",
    "print(f\"\\nPercentage of data retained: {retention_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2abb40",
   "metadata": {},
   "source": [
    "### 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e088d04b",
   "metadata": {},
   "source": [
    "#### 1.\n",
    "\n",
    "The code 'df.groupby(\"col1\")[\"col2\"].describe()' is demonstrated below. This groups data in 'col1' into groups based on having the same values. Then summary statistics are calculated using the groups 'col1' but using 'col2' data to get summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad592de",
   "metadata": {},
   "source": [
    "#### Code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e801e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          count        mean         std    min     25%    50%     75%    max\n",
      "Type 1                                                                      \n",
      "Bug        69.0  378.927536  117.875223  194.0  269.00  395.0  475.00  600.0\n",
      "Dark       31.0  445.741935  109.126217  220.0  359.00  465.0  510.00  680.0\n",
      "Dragon     32.0  550.531250  146.267538  300.0  420.00  600.0  680.00  780.0\n",
      "Electric   44.0  443.409091  105.721952  205.0  362.25  477.5  520.00  610.0\n",
      "Fairy      17.0  413.176471  123.781680  218.0  323.00  405.0  483.00  680.0\n",
      "Fighting   27.0  416.444444  102.464378  210.0  326.50  455.0  497.50  625.0\n",
      "Fire       52.0  458.076923  109.760496  250.0  368.00  482.0  534.00  680.0\n",
      "Flying      4.0  485.000000  161.400124  245.0  462.50  557.5  580.00  580.0\n",
      "Ghost      32.0  439.562500  110.072685  275.0  335.00  464.5  495.75  680.0\n",
      "Grass      70.0  421.142857  106.650626  180.0  318.50  430.0  497.00  630.0\n",
      "Ground     32.0  437.500000  123.913081  265.0  329.50  440.0  512.25  770.0\n",
      "Ice        24.0  433.458333  108.281027  250.0  305.00  467.5  526.25  580.0\n",
      "Normal     98.0  401.683673  115.733038  190.0  302.50  415.0  481.50  720.0\n",
      "Poison     28.0  399.142857   92.358687  245.0  323.75  401.5  490.00  535.0\n",
      "Psychic    57.0  475.947368  139.026645  198.0  336.00  485.0  600.00  780.0\n",
      "Rock       44.0  453.750000  108.059227  280.0  360.25  467.5  516.50  700.0\n",
      "Steel      27.0  487.703704  115.420907  300.0  425.00  500.0  580.00  700.0\n",
      "Water     112.0  430.455357  113.188266  200.0  328.75  455.0  502.25  770.0\n"
     ]
    }
   ],
   "source": [
    "pokemon_data = pd.read_csv('https://github.com/MainakRepositor/Datasets/raw/master/Pokemon.csv',encoding='ISO-8859-1')\n",
    "pokemon_data.head()\n",
    "result = pokemon_data.groupby(\"Type 1\")[\"Total\"].describe()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e61918",
   "metadata": {},
   "source": [
    "#### 2.\n",
    "\n",
    "##### What is df.describe() doing?\n",
    "The count here represents the number of non-null or non-missing values in each column. It depicts the presence of missing values in each column independently.\n",
    "\n",
    "##### What is df.groupby(\"col1\")[\"col2\"].describe() doing?\n",
    "The count here represents the number of non-null values of \"col2\" for each unique value in \"col1\". This is fundamentally different because:\n",
    "\n",
    "1. It is showing the distribution of data across groups defined by \"col1\".\n",
    "2. It allows us to compare the presence and characteristics of \"col2\" data across different groups in \"col1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dccf33f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "original_titanic_data_not_cleaned = pd.read_csv(url)\n",
    "print(original_titanic_data_not_cleaned.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b86c19",
   "metadata": {},
   "source": [
    "#### 3.\n",
    "\n",
    "\n",
    "I think that ChatGPT is better overall. This is because it does an excellent job tailoring solutions for my needs. Sometimes, searching Google is faster if it was a really complex issue which someone else has documented. I found a website called StackOverflow through Google which gave insightful results.\n",
    "\n",
    "ChatGPT only works well if given the code where the issue is caused. For example, if there is a missing bracket, showing ChatGPT the error is not enough to get a proper fix.\n",
    "\n",
    "For G., ChatGPT was more helpful as it recognized the error. I found Google was unhelpful.\n",
    "\n",
    "For each error I introduced, ChatGPT was more helpful and it was much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d181e23",
   "metadata": {},
   "source": [
    "### 9\n",
    "\n",
    "Yes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
