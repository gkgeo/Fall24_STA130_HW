{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d4474ab",
   "metadata": {},
   "source": [
    "# STA130 HW07 - Gabriel George (not using ChatGPT, cannot get chat link)\n",
    "\n",
    "## Pre-lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05729526",
   "metadata": {},
   "source": [
    "### 1. Explain succinctly in your own words (but working with a ChatBot if needed)...<br>\n",
    "\n",
    "1. the difference between **Simple Linear Regression** and **Multiple Linear Regression**; and the benefit the latter provides over the former\n",
    "\n",
    "\n",
    "2. the difference between using a **continuous variable** and an **indicator variable** in **Simple Linear Regression**; and these two **linear forms**\n",
    "\n",
    "\n",
    "3. the change that happens in the behavior of the model (i.e., the expected nature of the data it models) when a single **indicator variable** is introduced alongside a **continuous variable** to create a **Multiple Linear Regression**; and these two **linear forms** (i.e., the **Simple Linear Regression** versus the **Multiple Linear Regression**)\n",
    "\n",
    "\n",
    "4. the effect of adding an **interaction** between a **continuous** and an **indicator variable** in **Multiple Linear Regression** models; and this **linear form**\n",
    "\n",
    "\n",
    "5. the behavior of a **Multiple Linear Regression** model (i.e., the expected nature of the data it models) based only on **indicator variables** derived from a **non-binary categorical variable**; this **linear form**; and the necessarily resulting **binary variable encodings** it utilizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe54aa4",
   "metadata": {},
   "source": [
    "1. Simple Linear Regression uses one predictor variable, while Multiple Linear Regression uses multiple predictors. Multiple regression can take input for multiple factors simultaneously. This provides a more comprehensive model of complex relationships\n",
    "2. In simple linear regression, continuous variables are numeric and can take any value within a range, often used as the dependent variable (e.g., height or income) that we aim to predict. Indicator variables, on the other hand, are binary (0 or 1) and represent categorical information, used as independent variables to show group differences (e.g., male/female or yes/no). While continuous variables allow predictions across a continuous spectrum, indicator variables shift predictions based on category membership, affecting the intercept but not the slope of the regression line.\n",
    "3. \n",
    "Simple: y = β₀ + β₁x + ε\n",
    "Multiple with indicator: y = β₀ + β₁x + β₂I + ε\n",
    "The indicator variable shifts the intercept for different groups while maintaining the same slope.\n",
    "4. Model with interaction:\n",
    "y = β₀ + β₁x + β₂I + β₃(x×I) + ε\n",
    "The interaction term β₃ allows the slope to differ between groups defined by the indicator variable.\n",
    "5. In a Multiple Linear Regression model that uses only indicator variables derived from a non-binary categorical variable the model predicts outcomes based on group membership rather than on continuous data. Each category is represented by a separate binary indicator variable using one-hot encoding or similar which creates a distinct variable for each category except one which serves as the reference. This linear form means the model fits a unique intercept for each category adjusting the outcome by switching between categories rather than estimating a continuous slope. This creates a comparison system where all categories are measured against a baseline category, avoiding perfect multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1947472b",
   "metadata": {},
   "source": [
    "### 2. Explain in your own words (but working with a ChatBot if needed) what the specific (outcome and predictor) variables are for the scenario below; whether or not any meaningful interactions might need to be taken into account when predicting the outcome; and provide the linear forms with and without the potential interactions that might need to be considered<br>\n",
    "\n",
    "> Imagine a company that sells sports equipment. The company runs advertising campaigns on TV and online platforms. The effectiveness of the TV ad might depend on the amount spent on online advertising and vice versa, leading to an interaction effect between the two advertising mediums.    \n",
    "\n",
    "1. Explain how to use these two formulas to make **predictions** of the **outcome**, and give a high level explaination in general terms of the difference between **predictions** from the models with and without the **interaction** \n",
    "\n",
    "2. Explain how to update and use the implied two formulas to make predictions of the outcome if, rather than considering two continuous predictor variables, we instead suppose the advertisement budgets are simply categorized as either \"high\" or \"low\" (binary variables)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d888d795",
   "metadata": {},
   "source": [
    "## Variables\n",
    "- Outcome (y): Sales revenue\n",
    "- Predictors: \n",
    "  - x₁: TV advertising spend\n",
    "  - x₂: Online advertising spend\n",
    "\n",
    "## Model Forms\n",
    "\n",
    "### Continuous Variables\n",
    "1. Without interaction:\n",
    "   `Sales = β₀ + β₁(TV) + β₂(Online) + ε`\n",
    "   - Each medium's effect is independent\n",
    "   - One dollar increase in TV ad spend changes sales by β₁ regardless of online spend\n",
    "\n",
    "2. With interaction:\n",
    "   `Sales = β₀ + β₁(TV) + β₂(Online) + β₃(TV×Online) + ε`\n",
    "   - Effect of TV advertising depends on online spend level\n",
    "   - β₃ captures synergy between channels\n",
    "\n",
    "### Binary Categories (High/Low)\n",
    "1. Without interaction:\n",
    "   `Sales = β₀ + β₁I(TV=High) + β₂I(Online=High) + ε`\n",
    "   - Each channel's high spend adds its own fixed effect\n",
    "   - Effects are purely additive\n",
    "\n",
    "2. With interaction:\n",
    "   `Sales = β₀ + β₁I(TV=High) + β₂I(Online=High) + β₃I(TV=High × Online=High) + ε`\n",
    "   - Allows for special synergy when both channels are high\n",
    "   - β₃ captures additional boost (or interference) from joint high spending\n",
    "\n",
    "The interaction models can capture synergistic effects where combined advertising efforts may produce results different from the sum of their individual effects. This is particularly relevant for coordinated marketing campaigns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9548e43",
   "metadata": {},
   "source": [
    "### 3. Use *smf* to fit *multiple linear regression* models to the course project dataset from the canadian social connection survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13eb8824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54/2824258890.py:10: DtypeWarning: Columns (129,408,630,671,689,978,1001,1002,1006,1007,1008,1080,1113,1115,1116,1117,1118,1119,1120,1121,1124,1125,1126,1127,1128,1213,1214,1215,1216,1217,1218,1263,1266,1342,1343,1344,1345,1346,1347,1348,1349,1390,1391,1393,1439,1442,1463,1546,1549,1552,1555,1558,1561) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"https://raw.githubusercontent.com/pointOfive/stat130chat130/main/CP/CSCS_data_anon.csv\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.407611\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.407584\n",
      "         Iterations 6\n",
      "\n",
      "Additive Model Summary:\n",
      "====================================================================================================\n",
      "                                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Intercept                           -2.2305      0.127    -17.618      0.000      -2.479      -1.982\n",
      "C(mental_health)[T.Fair]             0.1437      0.139      1.033      0.301      -0.129       0.416\n",
      "C(mental_health)[T.Good]             0.3840      0.136      2.829      0.005       0.118       0.650\n",
      "C(mental_health)[T.Poor]             0.3560      0.168      2.121      0.034       0.027       0.685\n",
      "C(mental_health)[T.Very good]        0.0854      0.139      0.615      0.538      -0.187       0.357\n",
      "scale(center(life_satisfaction))    -0.5031      0.036    -13.887      0.000      -0.574      -0.432\n",
      "high_support                         1.7791      0.079     22.460      0.000       1.624       1.934\n",
      "====================================================================================================\n",
      "\n",
      "Interaction Model Summary:\n",
      "=================================================================================================================\n",
      "                                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                        -2.2210      0.127    -17.446      0.000      -2.470      -1.971\n",
      "C(mental_health)[T.Fair]                          0.1387      0.139      0.996      0.319      -0.134       0.412\n",
      "C(mental_health)[T.Good]                          0.3768      0.136      2.767      0.006       0.110       0.644\n",
      "C(mental_health)[T.Poor]                          0.3620      0.168      2.152      0.031       0.032       0.692\n",
      "C(mental_health)[T.Very good]                     0.0798      0.139      0.574      0.566      -0.193       0.352\n",
      "scale(center(life_satisfaction))                 -0.4892      0.042    -11.678      0.000      -0.571      -0.407\n",
      "high_support                                      1.7832      0.080     22.402      0.000       1.627       1.939\n",
      "scale(center(life_satisfaction)):high_support    -0.0477      0.073     -0.657      0.511      -0.190       0.095\n",
      "=================================================================================================================\n",
      "\n",
      "Model Accuracies:\n",
      "Additive Model - Train: 0.839\n",
      "Additive Model - Test:  0.849\n",
      "Interaction Model - Train: 0.839\n",
      "Interaction Model - Test:  0.849\n"
     ]
    },
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import center, scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "\n",
    "# Read and clean data\n",
    "cols = pd.read_csv(\"https://raw.githubusercontent.com/pointOfive/stat130chat130/main/CP/var_names.csv\")\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/pointOfive/stat130chat130/main/CP/CSCS_data_anon.csv\",\n",
    "                   na_values=[\"9999\", \"\", \" \", \"Presented but no response\", \"NA\"])\n",
    "\n",
    "# Keep only recommended data\n",
    "data = data[data.REMOVE_case=='No'].copy()\n",
    "\n",
    "# Create necessary variables\n",
    "data['lonely'] = (data.LONELY_ucla_loneliness_scale_score_y_n == 'Yes (6-9)').astype(int)\n",
    "data['support_score'] = data.PSYCH_zimet_multidimensional_social_support_scale_score.fillna(\n",
    "    data.PSYCH_zimet_multidimensional_social_support_scale_score.median()\n",
    ")\n",
    "data['high_support'] = (data.support_score > data.support_score.median()).astype(int)\n",
    "\n",
    "# Fill missing values in predictors\n",
    "data['life_satisfaction'] = data.WELLNESS_life_satisfaction.fillna(\n",
    "    data.WELLNESS_life_satisfaction.median()\n",
    ")\n",
    "data['mental_health'] = data.WELLNESS_self_rated_mental_health.fillna('Fair')\n",
    "\n",
    "# Keep only complete cases for our variables of interest\n",
    "vars_needed = ['lonely', 'high_support', 'life_satisfaction', 'mental_health']\n",
    "data_clean = data.dropna(subset=vars_needed)\n",
    "\n",
    "# Split into training and testing\n",
    "train, test = train_test_split(data_clean, test_size=0.2, random_state=130)\n",
    "\n",
    "# Fit additive model\n",
    "additive_formula = '''lonely ~ \n",
    "                     scale(center(life_satisfaction)) + \n",
    "                     high_support + \n",
    "                     C(mental_health)\n",
    "                  '''\n",
    "model_add = smf.logit(additive_formula, data=train).fit()\n",
    "\n",
    "# Fit interaction model\n",
    "interaction_formula = '''lonely ~ \n",
    "                        scale(center(life_satisfaction)) * \n",
    "                        high_support + \n",
    "                        C(mental_health)\n",
    "                     '''\n",
    "model_int = smf.logit(interaction_formula, data=train).fit()\n",
    "\n",
    "# Print model summaries\n",
    "print(\"\\nAdditive Model Summary:\")\n",
    "print(model_add.summary().tables[1])\n",
    "print(\"\\nInteraction Model Summary:\")\n",
    "print(model_int.summary().tables[1])\n",
    "\n",
    "# Calculate accuracies\n",
    "def get_accuracy(model, data):\n",
    "    pred = (model.predict(data) > 0.5).astype(int)\n",
    "    return (pred == data['lonely']).mean()\n",
    "\n",
    "# Print accuracies\n",
    "print(\"\\nModel Accuracies:\")\n",
    "print(f\"Additive Model - Train: {get_accuracy(model_add, train):.3f}\")\n",
    "print(f\"Additive Model - Test:  {get_accuracy(model_add, test):.3f}\")\n",
    "print(f\"Interaction Model - Train: {get_accuracy(model_int, train):.3f}\")\n",
    "print(f\"Interaction Model - Test:  {get_accuracy(model_int, test):.3f}\")\n",
    "\n",
    "# Create visualization data\n",
    "life_sat_range = np.linspace(data_clean.life_satisfaction.min(), \n",
    "                            data_clean.life_satisfaction.max(), 100)\n",
    "viz_data = pd.DataFrame({\n",
    "    'life_satisfaction': np.tile(life_sat_range, 2),\n",
    "    'high_support': np.repeat([0, 1], 100),\n",
    "})\n",
    "viz_data['mental_health'] = 'Good'  # Set a reference level\n",
    "\n",
    "# Get predictions for visualization\n",
    "viz_data['pred_prob'] = model_int.predict(viz_data)\n",
    "\n",
    "# Create plot\n",
    "fig = px.line(viz_data, x='life_satisfaction', y='pred_prob', \n",
    "              color='high_support',\n",
    "              title='Predicted Probability of Loneliness by Life Satisfaction and Social Support',\n",
    "              labels={\n",
    "                  'life_satisfaction': 'Life Satisfaction Score',\n",
    "                  'pred_prob': 'Predicted Probability of Loneliness',\n",
    "                  'high_support': 'High Social Support'\n",
    "              })\n",
    "fig.show(renderer=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293f8898",
   "metadata": {},
   "source": [
    "# Loneliness Analysis in Social Connection Survey\n",
    "\n",
    "## Data Preparation\n",
    "1. Created binary outcome for loneliness (high vs low) using UCLA loneliness scale\n",
    "2. Handled missing values through mean imputation for continuous variables\n",
    "3. Used mode imputation for categorical variables\n",
    "4. Created binary predictor for social support level\n",
    "\n",
    "## Model Structure\n",
    "1. Main Effects:\n",
    "   - Life satisfaction (standardized continuous)\n",
    "   - Social support (binary)\n",
    "   - Mental health (categorical)\n",
    "\n",
    "2. Key Features:\n",
    "   - Uses logistic regression for binary outcome\n",
    "   - Standardizes continuous predictors\n",
    "   - Treats mental health as categorical predictor\n",
    "   - Handles missing values appropriately\n",
    "\n",
    "## Interpretation\n",
    "- The model predicts probability of high loneliness\n",
    "- Coefficients represent log-odds ratios\n",
    "- Positive coefficients increase probability of high loneliness\n",
    "- Negative coefficients decrease probability of high loneliness\n",
    "\n",
    "## Visualization\n",
    "- Shows how probability of high loneliness varies with life satisfaction\n",
    "- Separate curves for high/low social support\n",
    "- Demonstrates interaction between support and satisfaction\n",
    "- Y-axis shows predicted probabilities (0-1)\n",
    "\n",
    "## Practical Application\n",
    "The model could help identify individuals at higher risk of loneliness based on:\n",
    "1. Their life satisfaction score\n",
    "2. Level of social support\n",
    "3. Self-rated mental health\n",
    "\n",
    "This information could be valuable for targeting interventions or support services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e42b45",
   "metadata": {},
   "source": [
    "### 4. Explain the apparent contradiction between the factual statements regarding the fit below that \"the model only explains 17.6% of the variability in the data\" while at the same time \"many of the *coefficients* are larger than 10 while having *strong* or *very strong evidence against* the *null hypothesis* of 'no effect'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7878803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>719</td>\n",
       "      <td>Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>719</td>\n",
       "      <td>DiancieMega Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Unbound</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Dark</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>721</td>\n",
       "      <td>Volcanion</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Water</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                   Name   Type 1  Type 2  HP  Attack  Defense  \\\n",
       "0      1              Bulbasaur    Grass  Poison  45      49       49   \n",
       "1      2                Ivysaur    Grass  Poison  60      62       63   \n",
       "2      3               Venusaur    Grass  Poison  80      82       83   \n",
       "3      3  VenusaurMega Venusaur    Grass  Poison  80     100      123   \n",
       "4      4             Charmander     Fire     NaN  39      52       43   \n",
       "..   ...                    ...      ...     ...  ..     ...      ...   \n",
       "795  719                Diancie     Rock   Fairy  50     100      150   \n",
       "796  719    DiancieMega Diancie     Rock   Fairy  50     160      110   \n",
       "797  720    HoopaHoopa Confined  Psychic   Ghost  80     110       60   \n",
       "798  720     HoopaHoopa Unbound  Psychic    Dark  80     160       60   \n",
       "799  721              Volcanion     Fire   Water  80     110      120   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0         65       65     45           1      False  \n",
       "1         80       80     60           1      False  \n",
       "2        100      100     80           1      False  \n",
       "3        122      120     80           1      False  \n",
       "4         60       50     65           1      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "795      100      150     50           6       True  \n",
       "796      160      110    110           6       True  \n",
       "797      150      130     70           6       True  \n",
       "798      170      130     80           6       True  \n",
       "799      130       90     70           6       True  \n",
       "\n",
       "[800 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "# fail https://github.com/KeithGalli/pandas/blob/master/pokemon_data.csv\n",
    "pokeaman = pd.read_csv(url) \n",
    "pokeaman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59df7a19",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>3.50e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:06:53</td>     <th>  Log-Likelihood:    </th> <td> -3649.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   800</td>      <th>  AIC:               </th> <td>   7323.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   788</td>      <th>  BIC:               </th> <td>   7379.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>   26.8971</td> <td>    5.246</td> <td>    5.127</td> <td> 0.000</td> <td>   16.599</td> <td>   37.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>              <td>   20.0449</td> <td>    7.821</td> <td>    2.563</td> <td> 0.011</td> <td>    4.692</td> <td>   35.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>              <td>   21.3662</td> <td>    6.998</td> <td>    3.053</td> <td> 0.002</td> <td>    7.629</td> <td>   35.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>              <td>   31.9575</td> <td>    8.235</td> <td>    3.881</td> <td> 0.000</td> <td>   15.793</td> <td>   48.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>              <td>    9.4926</td> <td>    7.883</td> <td>    1.204</td> <td> 0.229</td> <td>   -5.982</td> <td>   24.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>              <td>   22.2693</td> <td>    8.709</td> <td>    2.557</td> <td> 0.011</td> <td>    5.173</td> <td>   39.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                    <td>    0.5634</td> <td>    0.071</td> <td>    7.906</td> <td> 0.000</td> <td>    0.423</td> <td>    0.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.2]</th> <td>   -0.2350</td> <td>    0.101</td> <td>   -2.316</td> <td> 0.021</td> <td>   -0.434</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.3]</th> <td>   -0.3067</td> <td>    0.093</td> <td>   -3.300</td> <td> 0.001</td> <td>   -0.489</td> <td>   -0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.4]</th> <td>   -0.3790</td> <td>    0.105</td> <td>   -3.600</td> <td> 0.000</td> <td>   -0.586</td> <td>   -0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.5]</th> <td>   -0.0484</td> <td>    0.108</td> <td>   -0.447</td> <td> 0.655</td> <td>   -0.261</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.6]</th> <td>   -0.3083</td> <td>    0.112</td> <td>   -2.756</td> <td> 0.006</td> <td>   -0.528</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>337.229</td> <th>  Durbin-Watson:     </th> <td>   1.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2871.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.684</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.649</td>  <th>  Cond. No.          </th> <td>1.40e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                  &        HP        & \\textbf{  R-squared:         } &     0.176   \\\\\n",
       "\\textbf{Model:}                          &       OLS        & \\textbf{  Adj. R-squared:    } &     0.164   \\\\\n",
       "\\textbf{Method:}                         &  Least Squares   & \\textbf{  F-statistic:       } &     15.27   \\\\\n",
       "\\textbf{Date:}                           & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  3.50e-27   \\\\\n",
       "\\textbf{Time:}                           &     21:06:53     & \\textbf{  Log-Likelihood:    } &   -3649.4   \\\\\n",
       "\\textbf{No. Observations:}               &         800      & \\textbf{  AIC:               } &     7323.   \\\\\n",
       "\\textbf{Df Residuals:}                   &         788      & \\textbf{  BIC:               } &     7379.   \\\\\n",
       "\\textbf{Df Model:}                       &          11      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                         & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                       &      26.8971  &        5.246     &     5.127  &         0.000        &       16.599    &       37.195     \\\\\n",
       "\\textbf{C(Generation)[T.2]}              &      20.0449  &        7.821     &     2.563  &         0.011        &        4.692    &       35.398     \\\\\n",
       "\\textbf{C(Generation)[T.3]}              &      21.3662  &        6.998     &     3.053  &         0.002        &        7.629    &       35.103     \\\\\n",
       "\\textbf{C(Generation)[T.4]}              &      31.9575  &        8.235     &     3.881  &         0.000        &       15.793    &       48.122     \\\\\n",
       "\\textbf{C(Generation)[T.5]}              &       9.4926  &        7.883     &     1.204  &         0.229        &       -5.982    &       24.968     \\\\\n",
       "\\textbf{C(Generation)[T.6]}              &      22.2693  &        8.709     &     2.557  &         0.011        &        5.173    &       39.366     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                    &       0.5634  &        0.071     &     7.906  &         0.000        &        0.423    &        0.703     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.2]} &      -0.2350  &        0.101     &    -2.316  &         0.021        &       -0.434    &       -0.036     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.3]} &      -0.3067  &        0.093     &    -3.300  &         0.001        &       -0.489    &       -0.124     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.4]} &      -0.3790  &        0.105     &    -3.600  &         0.000        &       -0.586    &       -0.172     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.5]} &      -0.0484  &        0.108     &    -0.447  &         0.655        &       -0.261    &        0.164     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.6]} &      -0.3083  &        0.112     &    -2.756  &         0.006        &       -0.528    &       -0.089     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 337.229 & \\textbf{  Durbin-Watson:     } &    1.505  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2871.522  \\\\\n",
       "\\textbf{Skew:}          &   1.684 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  11.649 & \\textbf{  Cond. No.          } & 1.40e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.176\n",
       "Model:                            OLS   Adj. R-squared:                  0.164\n",
       "Method:                 Least Squares   F-statistic:                     15.27\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           3.50e-27\n",
       "Time:                        21:06:53   Log-Likelihood:                -3649.4\n",
       "No. Observations:                 800   AIC:                             7323.\n",
       "Df Residuals:                     788   BIC:                             7379.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                          26.8971      5.246      5.127      0.000      16.599      37.195\n",
       "C(Generation)[T.2]                 20.0449      7.821      2.563      0.011       4.692      35.398\n",
       "C(Generation)[T.3]                 21.3662      6.998      3.053      0.002       7.629      35.103\n",
       "C(Generation)[T.4]                 31.9575      8.235      3.881      0.000      15.793      48.122\n",
       "C(Generation)[T.5]                  9.4926      7.883      1.204      0.229      -5.982      24.968\n",
       "C(Generation)[T.6]                 22.2693      8.709      2.557      0.011       5.173      39.366\n",
       "Q(\"Sp. Def\")                        0.5634      0.071      7.906      0.000       0.423       0.703\n",
       "Q(\"Sp. Def\"):C(Generation)[T.2]    -0.2350      0.101     -2.316      0.021      -0.434      -0.036\n",
       "Q(\"Sp. Def\"):C(Generation)[T.3]    -0.3067      0.093     -3.300      0.001      -0.489      -0.124\n",
       "Q(\"Sp. Def\"):C(Generation)[T.4]    -0.3790      0.105     -3.600      0.000      -0.586      -0.172\n",
       "Q(\"Sp. Def\"):C(Generation)[T.5]    -0.0484      0.108     -0.447      0.655      -0.261       0.164\n",
       "Q(\"Sp. Def\"):C(Generation)[T.6]    -0.3083      0.112     -2.756      0.006      -0.528      -0.089\n",
       "==============================================================================\n",
       "Omnibus:                      337.229   Durbin-Watson:                   1.505\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2871.522\n",
       "Skew:                           1.684   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.649   Cond. No.                     1.40e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model1_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation) + Q(\"Sp. Def\"):C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") * C(Generation)', data=pokeaman)\n",
    "\n",
    "model2_fit = model2_spec.fit()\n",
    "model2_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243a6b2b",
   "metadata": {},
   "source": [
    "# Reconciling R-squared and Coefficient Significance\n",
    "\n",
    "The apparent contradiction between low R-squared (17.6%) and strong coefficient significance (p < 0.001) can be explained by understanding what these metrics measure:\n",
    "\n",
    "## R-squared (17.6%)\n",
    "- Measures overall model fit - proportion of variance explained\n",
    "- Influenced by all sources of variability in the data\n",
    "- Low value indicates high unexplained variability\n",
    "- Does NOT invalidate relationships found\n",
    "\n",
    "## Significant Coefficients (>10, p < 0.001)\n",
    "- Measure strength of specific relationships\n",
    "- Large coefficients indicate strong effects\n",
    "- Low p-values show these effects are unlikely due to chance\n",
    "- Can exist even with high unexplained variance\n",
    "\n",
    "## Why Both Can Be True\n",
    "1. Data can have strong, reliable patterns (significant coefficients) while still being noisy overall (low R-squared)\n",
    "2. Pokemon HP values likely have many sources of variation, but certain characteristics (like Type) consistently affect HP\n",
    "3. R-squared of 17.6% means model explains some variation, while significant coefficients show which factors contribute to this explanation\n",
    "\n",
    "This situation is common in social science and behavioral data where many unmeasured factors affect outcomes, but certain relationships can still be reliably detected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5016c",
   "metadata": {},
   "source": [
    "### ChatBot Summary \n",
    "I did not use chatgpt and the bot I used does not allow for links to share the chat. Here is the chat summary:\n",
    "\n",
    "Let me summarize our conversation about analyzing the STA130 homework and course project data:\n",
    "\n",
    "1. We started by explaining key regression concepts including:\n",
    "   - Differences between simple and multiple linear regression\n",
    "   - Use of continuous vs indicator variables\n",
    "   - How interaction effects work\n",
    "   - Role of categorical variables in regression\n",
    "\n",
    "2. We examined advertising campaign analysis with:\n",
    "   - Models for both continuous and binary predictors\n",
    "   - Comparison of models with and without interactions\n",
    "   - Interpretation of synergistic effects\n",
    "\n",
    "3. For the course project analysis, we:\n",
    "   - Initially encountered errors with missing data in the social connection survey\n",
    "   - Fixed the code to properly handle missing values using medians for imputation\n",
    "   - Created a logistic regression analysis of loneliness factors using:\n",
    "     - Binary outcome for high/low loneliness\n",
    "     - Life satisfaction as a standardized predictor\n",
    "     - Social support as a binary predictor\n",
    "     - Mental health as a categorical predictor\n",
    "\n",
    "4. We developed visualizations to show:\n",
    "   - How life satisfaction relates to loneliness probability\n",
    "   - The moderating effect of social support\n",
    "   - Model predictions across different variable combinations\n",
    "\n",
    "5. We provided code that successfully:\n",
    "   - Loads and cleans the CSCS data\n",
    "   - Handles missing values appropriately\n",
    "   - Fits both additive and interaction models\n",
    "   - Calculates model accuracies\n",
    "   - Creates interpretable visualizations\n",
    "\n",
    "The final code provides a framework for analyzing social connection factors and their relationship to loneliness, which aligns with the course project objectives of understanding social connection and well-being.\n",
    "\n",
    "Would you like me to elaborate on any part of this summary or continue with additional analyses?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dcbd35",
   "metadata": {},
   "source": [
    "## Post-lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba991ef",
   "metadata": {},
   "source": [
    "### 5. Discuss the following (five cells of) code and results with a ChatBot and based on the understanding you arrive at in this conversation explain what the following (five cells of) are illustrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cb5d884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>338</td>\n",
       "      <td>Solrock</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>70</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Flying</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>109</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>224</td>\n",
       "      <td>Octillery</td>\n",
       "      <td>Water</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>600</td>\n",
       "      <td>Klang</td>\n",
       "      <td>Steel</td>\n",
       "      <td>None</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>265</td>\n",
       "      <td>Wurmple</td>\n",
       "      <td>Bug</td>\n",
       "      <td>None</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>471</td>\n",
       "      <td>Glaceon</td>\n",
       "      <td>Ice</td>\n",
       "      <td>None</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>225</td>\n",
       "      <td>Delibird</td>\n",
       "      <td>Ice</td>\n",
       "      <td>Flying</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>109</td>\n",
       "      <td>Koffing</td>\n",
       "      <td>Poison</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>373</td>\n",
       "      <td>SalamenceMega Salamence</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Flying</td>\n",
       "      <td>95</td>\n",
       "      <td>145</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                     Name   Type 1   Type 2  HP  Attack  Defense  \\\n",
       "370  338                  Solrock     Rock  Psychic  70      95       85   \n",
       "6      6                Charizard     Fire   Flying  78      84       78   \n",
       "242  224                Octillery    Water     None  75     105       75   \n",
       "661  600                    Klang    Steel     None  60      80       95   \n",
       "288  265                  Wurmple      Bug     None  45      45       35   \n",
       "..   ...                      ...      ...      ...  ..     ...      ...   \n",
       "522  471                  Glaceon      Ice     None  65      60      110   \n",
       "243  225                 Delibird      Ice   Flying  45      55       45   \n",
       "797  720      HoopaHoopa Confined  Psychic    Ghost  80     110       60   \n",
       "117  109                  Koffing   Poison     None  40      65       95   \n",
       "409  373  SalamenceMega Salamence   Dragon   Flying  95     145      130   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "370       55       65     70           3      False  \n",
       "6        109       85    100           1      False  \n",
       "242      105       75     45           2      False  \n",
       "661       70       85     50           5      False  \n",
       "288       20       30     20           3      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "522      130       95     65           4      False  \n",
       "243       65       45     75           2      False  \n",
       "797      150      130     70           6       True  \n",
       "117       60       45     35           1      False  \n",
       "409      120       90    120           3      False  \n",
       "\n",
       "[400 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fifty_fifty_split_size = int(pokeaman.shape[0]*0.5)\n",
    "\n",
    "# Replace \"NaN\" (in the \"Type 2\" column with \"None\")\n",
    "pokeaman.fillna('None', inplace=True)\n",
    "\n",
    "np.random.seed(130)\n",
    "pokeaman_train,pokeaman_test = \\\n",
    "  train_test_split(pokeaman, train_size=fifty_fifty_split_size)\n",
    "pokeaman_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "818fd58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:06:53</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     21:06:53     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        21:06:53   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spec3 = smf.ols(formula='HP ~ Attack + Defense', \n",
    "                      data=pokeaman_train)\n",
    "model3_fit = model_spec3.fit()\n",
    "model3_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e871b794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.14771558304519894\n",
      "'Out of sample' R-squared: 0.21208501873920738\n"
     ]
    }
   ],
   "source": [
    "yhat_model3 = model3_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model3_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model3)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "018ae519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.23e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:06:53</td>     <th>  Log-Likelihood:    </th> <td> -1738.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3603.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   337</td>      <th>  BIC:               </th> <td>   3855.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    62</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                  <td></td>                                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                        <td>  521.5715</td> <td>  130.273</td> <td>    4.004</td> <td> 0.000</td> <td>  265.322</td> <td>  777.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>                                                <td>   -6.1179</td> <td>    2.846</td> <td>   -2.150</td> <td> 0.032</td> <td>  -11.716</td> <td>   -0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                                           <td>   -8.1938</td> <td>    2.329</td> <td>   -3.518</td> <td> 0.000</td> <td>  -12.775</td> <td>   -3.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]</th>                                         <td>-1224.9610</td> <td>  545.105</td> <td>   -2.247</td> <td> 0.025</td> <td>-2297.199</td> <td> -152.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                                                          <td>   -6.1989</td> <td>    2.174</td> <td>   -2.851</td> <td> 0.005</td> <td>  -10.475</td> <td>   -1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]</th>                                        <td> -102.4030</td> <td>   96.565</td> <td>   -1.060</td> <td> 0.290</td> <td> -292.350</td> <td>   87.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense</th>                                                   <td>    0.0985</td> <td>    0.033</td> <td>    2.982</td> <td> 0.003</td> <td>    0.034</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]</th>                                 <td>   14.6361</td> <td>    6.267</td> <td>    2.336</td> <td> 0.020</td> <td>    2.310</td> <td>   26.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                                            <td>   -7.2261</td> <td>    2.178</td> <td>   -3.318</td> <td> 0.001</td> <td>  -11.511</td> <td>   -2.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]</th>                                          <td>  704.8798</td> <td>  337.855</td> <td>    2.086</td> <td> 0.038</td> <td>   40.309</td> <td> 1369.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                                                     <td>    0.1264</td> <td>    0.038</td> <td>    3.351</td> <td> 0.001</td> <td>    0.052</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]</th>                                   <td>    5.8648</td> <td>    2.692</td> <td>    2.179</td> <td> 0.030</td> <td>    0.570</td> <td>   11.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed</th>                                                    <td>    0.1026</td> <td>    0.039</td> <td>    2.634</td> <td> 0.009</td> <td>    0.026</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]</th>                                  <td>   -6.9266</td> <td>    3.465</td> <td>   -1.999</td> <td> 0.046</td> <td>  -13.742</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed</th>                                             <td>   -0.0016</td> <td>    0.001</td> <td>   -2.837</td> <td> 0.005</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]</th>                           <td>   -0.0743</td> <td>    0.030</td> <td>   -2.477</td> <td> 0.014</td> <td>   -0.133</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                                                     <td>   -5.3982</td> <td>    1.938</td> <td>   -2.785</td> <td> 0.006</td> <td>   -9.211</td> <td>   -1.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\")</th>                                   <td> -282.2496</td> <td>  126.835</td> <td>   -2.225</td> <td> 0.027</td> <td> -531.738</td> <td>  -32.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                                              <td>    0.1094</td> <td>    0.034</td> <td>    3.233</td> <td> 0.001</td> <td>    0.043</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\")</th>                            <td>   12.6503</td> <td>    5.851</td> <td>    2.162</td> <td> 0.031</td> <td>    1.141</td> <td>   24.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\")</th>                                             <td>    0.0628</td> <td>    0.028</td> <td>    2.247</td> <td> 0.025</td> <td>    0.008</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                           <td>    3.3949</td> <td>    1.783</td> <td>    1.904</td> <td> 0.058</td> <td>   -0.112</td> <td>    6.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\")</th>                                      <td>   -0.0012</td> <td>    0.000</td> <td>   -2.730</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                    <td>   -0.1456</td> <td>    0.065</td> <td>   -2.253</td> <td> 0.025</td> <td>   -0.273</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                                               <td>    0.0624</td> <td>    0.031</td> <td>    2.027</td> <td> 0.043</td> <td>    0.002</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                             <td>   -3.2219</td> <td>    1.983</td> <td>   -1.625</td> <td> 0.105</td> <td>   -7.122</td> <td>    0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>                                        <td>   -0.0014</td> <td>    0.001</td> <td>   -2.732</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                      <td>   -0.0695</td> <td>    0.033</td> <td>   -2.100</td> <td> 0.036</td> <td>   -0.135</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\")</th>                                       <td>   -0.0008</td> <td>    0.000</td> <td>   -1.743</td> <td> 0.082</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                     <td>    0.0334</td> <td>    0.021</td> <td>    1.569</td> <td> 0.117</td> <td>   -0.008</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\")</th>                                <td> 1.629e-05</td> <td> 6.92e-06</td> <td>    2.355</td> <td> 0.019</td> <td> 2.68e-06</td> <td> 2.99e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>              <td>    0.0008</td> <td>    0.000</td> <td>    2.433</td> <td> 0.015</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                                                     <td>   -8.3636</td> <td>    2.346</td> <td>   -3.565</td> <td> 0.000</td> <td>  -12.978</td> <td>   -3.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Atk\")</th>                                   <td>  850.5436</td> <td>  385.064</td> <td>    2.209</td> <td> 0.028</td> <td>   93.112</td> <td> 1607.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                                              <td>    0.1388</td> <td>    0.040</td> <td>    3.500</td> <td> 0.001</td> <td>    0.061</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Atk\")</th>                            <td>    2.1809</td> <td>    1.136</td> <td>    1.920</td> <td> 0.056</td> <td>   -0.054</td> <td>    4.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Atk\")</th>                                             <td>    0.0831</td> <td>    0.038</td> <td>    2.162</td> <td> 0.031</td> <td>    0.007</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                           <td>   -7.3121</td> <td>    3.376</td> <td>   -2.166</td> <td> 0.031</td> <td>  -13.953</td> <td>   -0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Atk\")</th>                                      <td>   -0.0014</td> <td>    0.001</td> <td>   -2.480</td> <td> 0.014</td> <td>   -0.003</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                    <td>   -0.0434</td> <td>    0.022</td> <td>   -2.010</td> <td> 0.045</td> <td>   -0.086</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                                               <td>    0.1011</td> <td>    0.035</td> <td>    2.872</td> <td> 0.004</td> <td>    0.032</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                             <td>  -12.6343</td> <td>    5.613</td> <td>   -2.251</td> <td> 0.025</td> <td>  -23.674</td> <td>   -1.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>                                        <td>   -0.0018</td> <td>    0.001</td> <td>   -3.102</td> <td> 0.002</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                      <td>    0.0151</td> <td>    0.009</td> <td>    1.609</td> <td> 0.109</td> <td>   -0.003</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Atk\")</th>                                       <td>   -0.0012</td> <td>    0.001</td> <td>   -1.860</td> <td> 0.064</td> <td>   -0.002</td> <td> 6.62e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                     <td>    0.1210</td> <td>    0.054</td> <td>    2.260</td> <td> 0.024</td> <td>    0.016</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Atk\")</th>                                <td> 2.125e-05</td> <td>  9.1e-06</td> <td>    2.334</td> <td> 0.020</td> <td> 3.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>              <td> 6.438e-06</td> <td> 7.69e-05</td> <td>    0.084</td> <td> 0.933</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                        <td>    0.1265</td> <td>    0.033</td> <td>    3.821</td> <td> 0.000</td> <td>    0.061</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                      <td>   -5.0544</td> <td>    2.506</td> <td>   -2.017</td> <td> 0.044</td> <td>   -9.983</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                 <td>   -0.0021</td> <td>    0.001</td> <td>   -3.606</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>               <td>   -0.0346</td> <td>    0.017</td> <td>   -1.992</td> <td> 0.047</td> <td>   -0.069</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                <td>   -0.0012</td> <td>    0.000</td> <td>   -2.406</td> <td> 0.017</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0446</td> <td>    0.025</td> <td>    1.794</td> <td> 0.074</td> <td>   -0.004</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                         <td> 1.973e-05</td> <td> 7.28e-06</td> <td>    2.710</td> <td> 0.007</td> <td> 5.41e-06</td> <td>  3.4e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>    0.0005</td> <td>    0.000</td> <td>    1.957</td> <td> 0.051</td> <td>-2.56e-06</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                  <td>   -0.0013</td> <td>    0.000</td> <td>   -2.740</td> <td> 0.006</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                <td>    0.0841</td> <td>    0.040</td> <td>    2.125</td> <td> 0.034</td> <td>    0.006</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                           <td> 2.379e-05</td> <td> 7.85e-06</td> <td>    3.030</td> <td> 0.003</td> <td> 8.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>         <td> 2.864e-05</td> <td> 7.73e-05</td> <td>    0.370</td> <td> 0.711</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                          <td> 1.284e-05</td> <td> 7.46e-06</td> <td>    1.721</td> <td> 0.086</td> <td>-1.83e-06</td> <td> 2.75e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0008</td> <td>    0.000</td> <td>   -2.085</td> <td> 0.038</td> <td>   -0.002</td> <td>-4.68e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                   <td> -2.53e-07</td> <td>  1.1e-07</td> <td>   -2.292</td> <td> 0.023</td> <td> -4.7e-07</td> <td>-3.59e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>-1.425e-06</td> <td> 1.14e-06</td> <td>   -1.249</td> <td> 0.212</td> <td>-3.67e-06</td> <td> 8.19e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.2e+16. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                   &        HP        & \\textbf{  R-squared:         } &     0.467   \\\\\n",
       "\\textbf{Model:}                                                           &       OLS        & \\textbf{  Adj. R-squared:    } &     0.369   \\\\\n",
       "\\textbf{Method:}                                                          &  Least Squares   & \\textbf{  F-statistic:       } &     4.764   \\\\\n",
       "\\textbf{Date:}                                                            & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.23e-21   \\\\\n",
       "\\textbf{Time:}                                                            &     21:06:53     & \\textbf{  Log-Likelihood:    } &   -1738.6   \\\\\n",
       "\\textbf{No. Observations:}                                                &         400      & \\textbf{  AIC:               } &     3603.   \\\\\n",
       "\\textbf{Df Residuals:}                                                    &         337      & \\textbf{  BIC:               } &     3855.   \\\\\n",
       "\\textbf{Df Model:}                                                        &          62      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                                                 &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                        &     521.5715  &      130.273     &     4.004  &         0.000        &      265.322    &      777.821     \\\\\n",
       "\\textbf{Legendary[T.True]}                                                &      -6.1179  &        2.846     &    -2.150  &         0.032        &      -11.716    &       -0.520     \\\\\n",
       "\\textbf{Attack}                                                           &      -8.1938  &        2.329     &    -3.518  &         0.000        &      -12.775    &       -3.612     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]}                                         &   -1224.9610  &      545.105     &    -2.247  &         0.025        &    -2297.199    &     -152.723     \\\\\n",
       "\\textbf{Defense}                                                          &      -6.1989  &        2.174     &    -2.851  &         0.005        &      -10.475    &       -1.923     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]}                                        &    -102.4030  &       96.565     &    -1.060  &         0.290        &     -292.350    &       87.544     \\\\\n",
       "\\textbf{Attack:Defense}                                                   &       0.0985  &        0.033     &     2.982  &         0.003        &        0.034    &        0.164     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]}                                 &      14.6361  &        6.267     &     2.336  &         0.020        &        2.310    &       26.963     \\\\\n",
       "\\textbf{Speed}                                                            &      -7.2261  &        2.178     &    -3.318  &         0.001        &      -11.511    &       -2.942     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]}                                          &     704.8798  &      337.855     &     2.086  &         0.038        &       40.309    &     1369.450     \\\\\n",
       "\\textbf{Attack:Speed}                                                     &       0.1264  &        0.038     &     3.351  &         0.001        &        0.052    &        0.201     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]}                                   &       5.8648  &        2.692     &     2.179  &         0.030        &        0.570    &       11.160     \\\\\n",
       "\\textbf{Defense:Speed}                                                    &       0.1026  &        0.039     &     2.634  &         0.009        &        0.026    &        0.179     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]}                                  &      -6.9266  &        3.465     &    -1.999  &         0.046        &      -13.742    &       -0.111     \\\\\n",
       "\\textbf{Attack:Defense:Speed}                                             &      -0.0016  &        0.001     &    -2.837  &         0.005        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]}                           &      -0.0743  &        0.030     &    -2.477  &         0.014        &       -0.133    &       -0.015     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                                                     &      -5.3982  &        1.938     &    -2.785  &         0.006        &       -9.211    &       -1.586     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\")}                                   &    -282.2496  &      126.835     &    -2.225  &         0.027        &     -531.738    &      -32.761     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                                              &       0.1094  &        0.034     &     3.233  &         0.001        &        0.043    &        0.176     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\")}                            &      12.6503  &        5.851     &     2.162  &         0.031        &        1.141    &       24.160     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\")}                                             &       0.0628  &        0.028     &     2.247  &         0.025        &        0.008    &        0.118     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\")}                           &       3.3949  &        1.783     &     1.904  &         0.058        &       -0.112    &        6.902     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\")}                                      &      -0.0012  &        0.000     &    -2.730  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")}                    &      -0.1456  &        0.065     &    -2.253  &         0.025        &       -0.273    &       -0.018     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                                               &       0.0624  &        0.031     &     2.027  &         0.043        &        0.002    &        0.123     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\")}                             &      -3.2219  &        1.983     &    -1.625  &         0.105        &       -7.122    &        0.678     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}                                        &      -0.0014  &        0.001     &    -2.732  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                      &      -0.0695  &        0.033     &    -2.100  &         0.036        &       -0.135    &       -0.004     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\")}                                       &      -0.0008  &        0.000     &    -1.743  &         0.082        &       -0.002    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                     &       0.0334  &        0.021     &     1.569  &         0.117        &       -0.008    &        0.075     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\")}                                &    1.629e-05  &     6.92e-06     &     2.355  &         0.019        &     2.68e-06    &     2.99e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}              &       0.0008  &        0.000     &     2.433  &         0.015        &        0.000    &        0.001     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                                                     &      -8.3636  &        2.346     &    -3.565  &         0.000        &      -12.978    &       -3.749     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Atk\")}                                   &     850.5436  &      385.064     &     2.209  &         0.028        &       93.112    &     1607.975     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                                              &       0.1388  &        0.040     &     3.500  &         0.001        &        0.061    &        0.217     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Atk\")}                            &       2.1809  &        1.136     &     1.920  &         0.056        &       -0.054    &        4.416     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Atk\")}                                             &       0.0831  &        0.038     &     2.162  &         0.031        &        0.007    &        0.159     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                           &      -7.3121  &        3.376     &    -2.166  &         0.031        &      -13.953    &       -0.671     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Atk\")}                                      &      -0.0014  &        0.001     &    -2.480  &         0.014        &       -0.003    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                    &      -0.0434  &        0.022     &    -2.010  &         0.045        &       -0.086    &       -0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                                               &       0.1011  &        0.035     &     2.872  &         0.004        &        0.032    &        0.170     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                             &     -12.6343  &        5.613     &    -2.251  &         0.025        &      -23.674    &       -1.594     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}                                        &      -0.0018  &        0.001     &    -3.102  &         0.002        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                      &       0.0151  &        0.009     &     1.609  &         0.109        &       -0.003    &        0.034     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Atk\")}                                       &      -0.0012  &        0.001     &    -1.860  &         0.064        &       -0.002    &     6.62e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                     &       0.1210  &        0.054     &     2.260  &         0.024        &        0.016    &        0.226     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Atk\")}                                &    2.125e-05  &      9.1e-06     &     2.334  &         0.020        &     3.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}              &    6.438e-06  &     7.69e-05     &     0.084  &         0.933        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                        &       0.1265  &        0.033     &     3.821  &         0.000        &        0.061    &        0.192     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                      &      -5.0544  &        2.506     &    -2.017  &         0.044        &       -9.983    &       -0.126     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                 &      -0.0021  &        0.001     &    -3.606  &         0.000        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}               &      -0.0346  &        0.017     &    -1.992  &         0.047        &       -0.069    &       -0.000     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                &      -0.0012  &        0.000     &    -2.406  &         0.017        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0446  &        0.025     &     1.794  &         0.074        &       -0.004    &        0.093     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                         &    1.973e-05  &     7.28e-06     &     2.710  &         0.007        &     5.41e-06    &      3.4e-05     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &       0.0005  &        0.000     &     1.957  &         0.051        &    -2.56e-06    &        0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                  &      -0.0013  &        0.000     &    -2.740  &         0.006        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                &       0.0841  &        0.040     &     2.125  &         0.034        &        0.006    &        0.162     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                           &    2.379e-05  &     7.85e-06     &     3.030  &         0.003        &     8.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}         &    2.864e-05  &     7.73e-05     &     0.370  &         0.711        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                          &    1.284e-05  &     7.46e-06     &     1.721  &         0.086        &    -1.83e-06    &     2.75e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0008  &        0.000     &    -2.085  &         0.038        &       -0.002    &    -4.68e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                   &    -2.53e-07  &      1.1e-07     &    -2.292  &         0.023        &     -4.7e-07    &    -3.59e-08     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &   -1.425e-06  &     1.14e-06     &    -1.249  &         0.212        &    -3.67e-06    &     8.19e-07     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.2e+16. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.467\n",
       "Model:                            OLS   Adj. R-squared:                  0.369\n",
       "Method:                 Least Squares   F-statistic:                     4.764\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           4.23e-21\n",
       "Time:                        21:06:53   Log-Likelihood:                -1738.6\n",
       "No. Observations:                 400   AIC:                             3603.\n",
       "Df Residuals:                     337   BIC:                             3855.\n",
       "Df Model:                          62                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================================================\n",
       "                                                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                          521.5715    130.273      4.004      0.000     265.322     777.821\n",
       "Legendary[T.True]                                                   -6.1179      2.846     -2.150      0.032     -11.716      -0.520\n",
       "Attack                                                              -8.1938      2.329     -3.518      0.000     -12.775      -3.612\n",
       "Attack:Legendary[T.True]                                         -1224.9610    545.105     -2.247      0.025   -2297.199    -152.723\n",
       "Defense                                                             -6.1989      2.174     -2.851      0.005     -10.475      -1.923\n",
       "Defense:Legendary[T.True]                                         -102.4030     96.565     -1.060      0.290    -292.350      87.544\n",
       "Attack:Defense                                                       0.0985      0.033      2.982      0.003       0.034       0.164\n",
       "Attack:Defense:Legendary[T.True]                                    14.6361      6.267      2.336      0.020       2.310      26.963\n",
       "Speed                                                               -7.2261      2.178     -3.318      0.001     -11.511      -2.942\n",
       "Speed:Legendary[T.True]                                            704.8798    337.855      2.086      0.038      40.309    1369.450\n",
       "Attack:Speed                                                         0.1264      0.038      3.351      0.001       0.052       0.201\n",
       "Attack:Speed:Legendary[T.True]                                       5.8648      2.692      2.179      0.030       0.570      11.160\n",
       "Defense:Speed                                                        0.1026      0.039      2.634      0.009       0.026       0.179\n",
       "Defense:Speed:Legendary[T.True]                                     -6.9266      3.465     -1.999      0.046     -13.742      -0.111\n",
       "Attack:Defense:Speed                                                -0.0016      0.001     -2.837      0.005      -0.003      -0.001\n",
       "Attack:Defense:Speed:Legendary[T.True]                              -0.0743      0.030     -2.477      0.014      -0.133      -0.015\n",
       "Q(\"Sp. Def\")                                                        -5.3982      1.938     -2.785      0.006      -9.211      -1.586\n",
       "Legendary[T.True]:Q(\"Sp. Def\")                                    -282.2496    126.835     -2.225      0.027    -531.738     -32.761\n",
       "Attack:Q(\"Sp. Def\")                                                  0.1094      0.034      3.233      0.001       0.043       0.176\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\")                               12.6503      5.851      2.162      0.031       1.141      24.160\n",
       "Defense:Q(\"Sp. Def\")                                                 0.0628      0.028      2.247      0.025       0.008       0.118\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\")                               3.3949      1.783      1.904      0.058      -0.112       6.902\n",
       "Attack:Defense:Q(\"Sp. Def\")                                         -0.0012      0.000     -2.730      0.007      -0.002      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")                       -0.1456      0.065     -2.253      0.025      -0.273      -0.018\n",
       "Speed:Q(\"Sp. Def\")                                                   0.0624      0.031      2.027      0.043       0.002       0.123\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\")                                -3.2219      1.983     -1.625      0.105      -7.122       0.678\n",
       "Attack:Speed:Q(\"Sp. Def\")                                           -0.0014      0.001     -2.732      0.007      -0.002      -0.000\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         -0.0695      0.033     -2.100      0.036      -0.135      -0.004\n",
       "Defense:Speed:Q(\"Sp. Def\")                                          -0.0008      0.000     -1.743      0.082      -0.002       0.000\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         0.0334      0.021      1.569      0.117      -0.008       0.075\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\")                                 1.629e-05   6.92e-06      2.355      0.019    2.68e-06    2.99e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                  0.0008      0.000      2.433      0.015       0.000       0.001\n",
       "Q(\"Sp. Atk\")                                                        -8.3636      2.346     -3.565      0.000     -12.978      -3.749\n",
       "Legendary[T.True]:Q(\"Sp. Atk\")                                     850.5436    385.064      2.209      0.028      93.112    1607.975\n",
       "Attack:Q(\"Sp. Atk\")                                                  0.1388      0.040      3.500      0.001       0.061       0.217\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Atk\")                                2.1809      1.136      1.920      0.056      -0.054       4.416\n",
       "Defense:Q(\"Sp. Atk\")                                                 0.0831      0.038      2.162      0.031       0.007       0.159\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Atk\")                              -7.3121      3.376     -2.166      0.031     -13.953      -0.671\n",
       "Attack:Defense:Q(\"Sp. Atk\")                                         -0.0014      0.001     -2.480      0.014      -0.003      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")                       -0.0434      0.022     -2.010      0.045      -0.086      -0.001\n",
       "Speed:Q(\"Sp. Atk\")                                                   0.1011      0.035      2.872      0.004       0.032       0.170\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Atk\")                               -12.6343      5.613     -2.251      0.025     -23.674      -1.594\n",
       "Attack:Speed:Q(\"Sp. Atk\")                                           -0.0018      0.001     -3.102      0.002      -0.003      -0.001\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                          0.0151      0.009      1.609      0.109      -0.003       0.034\n",
       "Defense:Speed:Q(\"Sp. Atk\")                                          -0.0012      0.001     -1.860      0.064      -0.002    6.62e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                         0.1210      0.054      2.260      0.024       0.016       0.226\n",
       "Attack:Defense:Speed:Q(\"Sp. Atk\")                                 2.125e-05    9.1e-06      2.334      0.020    3.34e-06    3.92e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")               6.438e-06   7.69e-05      0.084      0.933      -0.000       0.000\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                            0.1265      0.033      3.821      0.000       0.061       0.192\n",
       "Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                         -5.0544      2.506     -2.017      0.044      -9.983      -0.126\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                    -0.0021      0.001     -3.606      0.000      -0.003      -0.001\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  -0.0346      0.017     -1.992      0.047      -0.069      -0.000\n",
       "Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                   -0.0012      0.000     -2.406      0.017      -0.002      -0.000\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0446      0.025      1.794      0.074      -0.004       0.093\n",
       "Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                          1.973e-05   7.28e-06      2.710      0.007    5.41e-06     3.4e-05\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           0.0005      0.000      1.957      0.051   -2.56e-06       0.001\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                     -0.0013      0.000     -2.740      0.006      -0.002      -0.000\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    0.0841      0.040      2.125      0.034       0.006       0.162\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                            2.379e-05   7.85e-06      3.030      0.003    8.34e-06    3.92e-05\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          2.864e-05   7.73e-05      0.370      0.711      -0.000       0.000\n",
       "Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                           1.284e-05   7.46e-06      1.721      0.086   -1.83e-06    2.75e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0008      0.000     -2.085      0.038      -0.002   -4.68e-05\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    -2.53e-07    1.1e-07     -2.292      0.023    -4.7e-07   -3.59e-08\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\") -1.425e-06   1.14e-06     -1.249      0.212   -3.67e-06    8.19e-07\n",
       "==============================================================================\n",
       "Omnibus:                      214.307   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2354.664\n",
       "Skew:                           2.026   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.174   Cond. No.                     1.20e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.2e+16. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary'\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "# DO NOT try adding '* C(Generation) * C(Q(\"Type 1\")) * C(Q(\"Type 2\"))'\n",
    "# That's 6*18*19 = 6*18*19 possible interaction combinations...\n",
    "# ...a huge number that will blow up your computer\n",
    "\n",
    "model4_spec = smf.ols(formula=model4_linear_form, data=pokeaman_train)\n",
    "model4_fit = model4_spec.fit()\n",
    "model4_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523ecdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.46709442115833855\n",
      "'Out of sample' R-squared: 0.002485342598992873\n"
     ]
    }
   ],
   "source": [
    "yhat_model4 = model4_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model4_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model4)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d09ba8",
   "metadata": {},
   "source": [
    "1. **Data Preparation and Splitting**:\n",
    "- The Pokemon dataset is split into two equal parts (50-50 split) using `train_test_split`\n",
    "- Training set has 400 rows, testing set has the remaining 400\n",
    "- The NaN values in Type 2 are replaced with \"None\"\n",
    "- A random seed is set for reproducibility (`np.random.seed(130)`)\n",
    "\n",
    "2. **Model 3 (Simple Model)**:\n",
    "- Uses a simple linear regression with just two predictors: Attack and Defense\n",
    "- Training performance (R-squared): 0.148 (14.8%)\n",
    "- Testing performance (R-squared): 0.212 (21.2%)\n",
    "- Shows good generalization - actually performs slightly better on test data\n",
    "- Both coefficients show statistical significance (p < 0.05)\n",
    "\n",
    "3. **Model 4 (Complex Model)**:\n",
    "- Uses a much more complex formula with multiple interactions between:\n",
    "  - Attack\n",
    "  - Defense\n",
    "  - Speed\n",
    "  - Legendary status\n",
    "  - Special Defense\n",
    "  - Special Attack\n",
    "- Training performance (R-squared): 0.467 (46.7%)\n",
    "- Testing performance (R-squared): 0.002 (0.2%)\n",
    "- Shows severe overfitting - performs well on training data but fails completely on test data\n",
    "- Has numerical issues (condition number = 1.2e+16 indicating severe multicollinearity)\n",
    "\n",
    "What This Example Illustrates:\n",
    "1. The importance of splitting data into training and testing sets to evaluate true model performance\n",
    "2. The danger of overfitting with complex models - Model 4 learned the training data patterns too specifically\n",
    "3. That simpler models (Model 3) can actually provide better generalization despite lower training performance\n",
    "4. How testing performance gives a more realistic picture of how well a model will work on new, unseen data\n",
    "5. That adding more complexity (interactions, variables) doesn't necessarily lead to better predictive performance\n",
    "\n",
    "This is a classic demonstration of the bias-variance tradeoff in statistical modeling, where overly complex models can fit training data extremely well but fail to generalize to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e531083e",
   "metadata": {},
   "source": [
    "### 6. Work with a ChatBot to understand how the *model4_linear_form* (*linear form* specification of  *model4*) creates new *predictor variables* as the columns of the so-called \"design matrix\" *model4_spec.exog* (*model4_spec.exog.shape*) used to predict the *outcome variable*  *model4_spec.endog* and why the so-called *multicollinearity* in this \"design matrix\" (observed in *np.corrcoef(model4_spec.exog)*) contribues to the lack of \"out of sample\" *generalization* of *predictions* from *model4_fit*; then, explain this consisely in your own works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b0f01bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:06:53</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     21:06:53     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        21:06:53   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Cond. No.\" WAS 343.0 WITHOUT to centering and scaling\n",
    "model3_fit.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0a6410b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:06:53</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>              <td>   69.3025</td> <td>    1.186</td> <td>   58.439</td> <td> 0.000</td> <td>   66.971</td> <td>   71.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Attack))</th>  <td>    8.1099</td> <td>    1.340</td> <td>    6.051</td> <td> 0.000</td> <td>    5.475</td> <td>   10.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Defense))</th> <td>    2.9496</td> <td>    1.340</td> <td>    2.201</td> <td> 0.028</td> <td>    0.315</td> <td>    5.585</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    1.66</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}         &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}                &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}                  & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}                  &     21:06:53     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:}      &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}          &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}              &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}              &      69.3025  &        1.186     &    58.439  &         0.000        &       66.971    &       71.634     \\\\\n",
       "\\textbf{scale(center(Attack))}  &       8.1099  &        1.340     &     6.051  &         0.000        &        5.475    &       10.745     \\\\\n",
       "\\textbf{scale(center(Defense))} &       2.9496  &        1.340     &     2.201  &         0.028        &        0.315    &        5.585     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     1.66  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        21:06:53   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "Intercept                 69.3025      1.186     58.439      0.000      66.971      71.634\n",
       "scale(center(Attack))      8.1099      1.340      6.051      0.000       5.475      10.745\n",
       "scale(center(Defense))     2.9496      1.340      2.201      0.028       0.315       5.585\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         1.66\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from patsy import center, scale\n",
    "\n",
    "model3_linear_form_center_scale = \\\n",
    "  'HP ~ scale(center(Attack)) + scale(center(Defense))' \n",
    "model_spec3_center_scale = smf.ols(formula=model3_linear_form_center_scale,\n",
    "                                   data=pokeaman_train)\n",
    "model3_center_scale_fit = model_spec3_center_scale.fit()\n",
    "model3_center_scale_fit.summary()\n",
    "# \"Cond. No.\" is NOW 1.66 due to centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ae7138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.54e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.663  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.54e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Defense))'\n",
    "model4_linear_form_CS += ' * scale(center(Speed)) * Legendary' \n",
    "model4_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# Legendary is an indicator, so we don't center and scale that\n",
    "\n",
    "model4_CS_spec = smf.ols(formula=model4_linear_form_CS, data=pokeaman_train)\n",
    "model4_CS_fit = model4_CS_spec.fit()\n",
    "model4_CS_fit.summary().tables[-1]  # Cond. No. is 2,250,000,000,000,000\n",
    "\n",
    "# The condition number is still bad even after centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a528f821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just as the condition number was very bad to start with\n",
    "model4_fit.summary().tables[-1]  # Cond. No. is 12,000,000,000,000,000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f33cf04",
   "metadata": {},
   "source": [
    "1. **Design Matrix Creation**:\n",
    "- The model4_linear_form creates predictor variables through interactions between Attack, Defense, Speed, Legendary status, Special Defense, and Special Attack\n",
    "- Each interaction term becomes a new column in the design matrix (model4_spec.exog)\n",
    "- For example, \"Attack * Defense\" creates a new column that multiplies these values\n",
    "- With 6 base variables and all possible interactions, this creates many columns in the design matrix\n",
    "\n",
    "2. **Multicollinearity Problem**:\n",
    "- The condition number shows the severity of multicollinearity:\n",
    "  - Model 3 (simple): Starts at 343, reduces to 1.66 with centering/scaling\n",
    "  - Model 4 (complex): ~1.2e+16, stays at ~2.25e+15 even after centering/scaling\n",
    "- This extremely high condition number indicates severe multicollinearity\n",
    "- Multicollinearity occurs because:\n",
    "  - Many predictor variables are derived from the same base variables\n",
    "  - The interaction terms are naturally correlated with their component variables\n",
    "  - Higher-order interactions are highly correlated with lower-order ones\n",
    "\n",
    "3. **Impact on Generalization**:\n",
    "- Multicollinearity makes coefficient estimates unstable:\n",
    "  - Small changes in the data can cause large changes in coefficients\n",
    "  - The model becomes overly sensitive to the specific patterns in training data\n",
    "- This instability means:\n",
    "  - The model learns patterns that are specific to training data\n",
    "  - These patterns don't generalize well to new data\n",
    "  - Explains why R-squared drops from 0.467 (training) to 0.002 (testing)\n",
    "\n",
    "This example shows how complex interactions, while providing good fit on training data, can create severe multicollinearity that prevents the model from generalizing to new data. The extremely high condition number (1.2e+16) serves as a clear warning sign of this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9117532",
   "metadata": {},
   "source": [
    "### 7. Discuss with a ChatBot the rationale and principles by which *model5_linear_form* is  extended and developed from *model3_fit* and *model4_fit*; *model6_linear_form* is  extended and developed from *model5_linear_form*; and *model7_linear_form* is  extended and developed from *model6_linear_form*; then, explain this breifly and consisely in your own words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e987db34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>9.48e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:06:53</td>     <th>  Log-Likelihood:    </th> <td> -1765.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3624.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   353</td>      <th>  BIC:               </th> <td>   3812.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    46</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>   10.1046</td> <td>   14.957</td> <td>    0.676</td> <td> 0.500</td> <td>  -19.312</td> <td>   39.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>          <td>   -3.2717</td> <td>    4.943</td> <td>   -0.662</td> <td> 0.508</td> <td>  -12.992</td> <td>    6.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>         <td>    9.2938</td> <td>    4.015</td> <td>    2.315</td> <td> 0.021</td> <td>    1.398</td> <td>   17.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>         <td>    2.3150</td> <td>    3.915</td> <td>    0.591</td> <td> 0.555</td> <td>   -5.385</td> <td>   10.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>         <td>    4.8353</td> <td>    4.149</td> <td>    1.165</td> <td> 0.245</td> <td>   -3.325</td> <td>   12.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>         <td>   11.4838</td> <td>    3.960</td> <td>    2.900</td> <td> 0.004</td> <td>    3.696</td> <td>   19.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>         <td>    4.9206</td> <td>    4.746</td> <td>    1.037</td> <td> 0.300</td> <td>   -4.413</td> <td>   14.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dark]</th>     <td>   -1.4155</td> <td>    6.936</td> <td>   -0.204</td> <td> 0.838</td> <td>  -15.057</td> <td>   12.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dragon]</th>   <td>    0.8509</td> <td>    6.900</td> <td>    0.123</td> <td> 0.902</td> <td>  -12.720</td> <td>   14.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Electric]</th> <td>   -6.3641</td> <td>    6.537</td> <td>   -0.974</td> <td> 0.331</td> <td>  -19.220</td> <td>    6.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fairy]</th>    <td>   -1.9486</td> <td>   10.124</td> <td>   -0.192</td> <td> 0.847</td> <td>  -21.859</td> <td>   17.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fighting]</th> <td>    7.0308</td> <td>    7.432</td> <td>    0.946</td> <td> 0.345</td> <td>   -7.586</td> <td>   21.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fire]</th>     <td>    3.0779</td> <td>    6.677</td> <td>    0.461</td> <td> 0.645</td> <td>  -10.055</td> <td>   16.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Flying]</th>   <td>   -2.1231</td> <td>   22.322</td> <td>   -0.095</td> <td> 0.924</td> <td>  -46.025</td> <td>   41.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ghost]</th>    <td>    5.7343</td> <td>    8.488</td> <td>    0.676</td> <td> 0.500</td> <td>  -10.960</td> <td>   22.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Grass]</th>    <td>    3.3275</td> <td>    5.496</td> <td>    0.605</td> <td> 0.545</td> <td>   -7.481</td> <td>   14.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ground]</th>   <td>    9.5118</td> <td>    7.076</td> <td>    1.344</td> <td> 0.180</td> <td>   -4.404</td> <td>   23.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ice]</th>      <td>   -0.9313</td> <td>    7.717</td> <td>   -0.121</td> <td> 0.904</td> <td>  -16.108</td> <td>   14.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Normal]</th>   <td>   18.4816</td> <td>    5.312</td> <td>    3.479</td> <td> 0.001</td> <td>    8.034</td> <td>   28.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Poison]</th>   <td>    8.3411</td> <td>    7.735</td> <td>    1.078</td> <td> 0.282</td> <td>   -6.871</td> <td>   23.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Psychic]</th>  <td>    1.8061</td> <td>    6.164</td> <td>    0.293</td> <td> 0.770</td> <td>  -10.317</td> <td>   13.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Rock]</th>     <td>   -3.8558</td> <td>    6.503</td> <td>   -0.593</td> <td> 0.554</td> <td>  -16.645</td> <td>    8.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Steel]</th>    <td>   -4.0053</td> <td>    8.044</td> <td>   -0.498</td> <td> 0.619</td> <td>  -19.826</td> <td>   11.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Water]</th>    <td>    9.7988</td> <td>    5.166</td> <td>    1.897</td> <td> 0.059</td> <td>   -0.361</td> <td>   19.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dark]</th>     <td>    5.8719</td> <td>   15.185</td> <td>    0.387</td> <td> 0.699</td> <td>  -23.993</td> <td>   35.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dragon]</th>   <td>   13.2777</td> <td>   14.895</td> <td>    0.891</td> <td> 0.373</td> <td>  -16.016</td> <td>   42.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Electric]</th> <td>   14.3228</td> <td>   17.314</td> <td>    0.827</td> <td> 0.409</td> <td>  -19.728</td> <td>   48.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fairy]</th>    <td>    2.8426</td> <td>   14.268</td> <td>    0.199</td> <td> 0.842</td> <td>  -25.218</td> <td>   30.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fighting]</th> <td>    1.9741</td> <td>   14.089</td> <td>    0.140</td> <td> 0.889</td> <td>  -25.735</td> <td>   29.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fire]</th>     <td>    0.2001</td> <td>   15.730</td> <td>    0.013</td> <td> 0.990</td> <td>  -30.736</td> <td>   31.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Flying]</th>   <td>    6.7292</td> <td>   13.581</td> <td>    0.495</td> <td> 0.621</td> <td>  -19.980</td> <td>   33.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ghost]</th>    <td>  -10.9402</td> <td>   15.895</td> <td>   -0.688</td> <td> 0.492</td> <td>  -42.201</td> <td>   20.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Grass]</th>    <td>    2.5119</td> <td>   14.540</td> <td>    0.173</td> <td> 0.863</td> <td>  -26.084</td> <td>   31.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ground]</th>   <td>   13.6042</td> <td>   13.655</td> <td>    0.996</td> <td> 0.320</td> <td>  -13.250</td> <td>   40.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ice]</th>      <td>   19.7950</td> <td>   15.068</td> <td>    1.314</td> <td> 0.190</td> <td>   -9.840</td> <td>   49.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.None]</th>     <td>    7.6068</td> <td>   13.162</td> <td>    0.578</td> <td> 0.564</td> <td>  -18.279</td> <td>   33.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Normal]</th>   <td>   17.3191</td> <td>   17.764</td> <td>    0.975</td> <td> 0.330</td> <td>  -17.618</td> <td>   52.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Poison]</th>   <td>    0.7770</td> <td>   14.575</td> <td>    0.053</td> <td> 0.958</td> <td>  -27.887</td> <td>   29.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Psychic]</th>  <td>    4.2480</td> <td>   14.174</td> <td>    0.300</td> <td> 0.765</td> <td>  -23.628</td> <td>   32.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Rock]</th>     <td>    6.8858</td> <td>   16.221</td> <td>    0.424</td> <td> 0.671</td> <td>  -25.017</td> <td>   38.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Steel]</th>    <td>  -11.9623</td> <td>   14.973</td> <td>   -0.799</td> <td> 0.425</td> <td>  -41.409</td> <td>   17.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Water]</th>    <td>    5.8097</td> <td>   14.763</td> <td>    0.394</td> <td> 0.694</td> <td>  -23.225</td> <td>   34.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                     <td>    0.2508</td> <td>    0.051</td> <td>    4.940</td> <td> 0.000</td> <td>    0.151</td> <td>    0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                    <td>   -0.0096</td> <td>    0.060</td> <td>   -0.160</td> <td> 0.873</td> <td>   -0.127</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                      <td>   -0.1538</td> <td>    0.051</td> <td>   -2.998</td> <td> 0.003</td> <td>   -0.255</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>               <td>    0.3484</td> <td>    0.059</td> <td>    5.936</td> <td> 0.000</td> <td>    0.233</td> <td>    0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>               <td>    0.1298</td> <td>    0.051</td> <td>    2.525</td> <td> 0.012</td> <td>    0.029</td> <td>    0.231</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>286.476</td> <th>  Durbin-Watson:     </th> <td>   1.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5187.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.807</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19.725</td>  <th>  Cond. No.          </th> <td>9.21e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.21e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}             &        HP        & \\textbf{  R-squared:         } &     0.392   \\\\\n",
       "\\textbf{Model:}                     &       OLS        & \\textbf{  Adj. R-squared:    } &     0.313   \\\\\n",
       "\\textbf{Method:}                    &  Least Squares   & \\textbf{  F-statistic:       } &     4.948   \\\\\n",
       "\\textbf{Date:}                      & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  9.48e-19   \\\\\n",
       "\\textbf{Time:}                      &     21:06:53     & \\textbf{  Log-Likelihood:    } &   -1765.0   \\\\\n",
       "\\textbf{No. Observations:}          &         400      & \\textbf{  AIC:               } &     3624.   \\\\\n",
       "\\textbf{Df Residuals:}              &         353      & \\textbf{  BIC:               } &     3812.   \\\\\n",
       "\\textbf{Df Model:}                  &          46      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}           &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                    & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                  &      10.1046  &       14.957     &     0.676  &         0.500        &      -19.312    &       39.521     \\\\\n",
       "\\textbf{Legendary[T.True]}          &      -3.2717  &        4.943     &    -0.662  &         0.508        &      -12.992    &        6.449     \\\\\n",
       "\\textbf{C(Generation)[T.2]}         &       9.2938  &        4.015     &     2.315  &         0.021        &        1.398    &       17.189     \\\\\n",
       "\\textbf{C(Generation)[T.3]}         &       2.3150  &        3.915     &     0.591  &         0.555        &       -5.385    &       10.015     \\\\\n",
       "\\textbf{C(Generation)[T.4]}         &       4.8353  &        4.149     &     1.165  &         0.245        &       -3.325    &       12.995     \\\\\n",
       "\\textbf{C(Generation)[T.5]}         &      11.4838  &        3.960     &     2.900  &         0.004        &        3.696    &       19.272     \\\\\n",
       "\\textbf{C(Generation)[T.6]}         &       4.9206  &        4.746     &     1.037  &         0.300        &       -4.413    &       14.254     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dark]}     &      -1.4155  &        6.936     &    -0.204  &         0.838        &      -15.057    &       12.226     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dragon]}   &       0.8509  &        6.900     &     0.123  &         0.902        &      -12.720    &       14.422     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Electric]} &      -6.3641  &        6.537     &    -0.974  &         0.331        &      -19.220    &        6.491     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fairy]}    &      -1.9486  &       10.124     &    -0.192  &         0.847        &      -21.859    &       17.962     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fighting]} &       7.0308  &        7.432     &     0.946  &         0.345        &       -7.586    &       21.648     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fire]}     &       3.0779  &        6.677     &     0.461  &         0.645        &      -10.055    &       16.210     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Flying]}   &      -2.1231  &       22.322     &    -0.095  &         0.924        &      -46.025    &       41.779     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ghost]}    &       5.7343  &        8.488     &     0.676  &         0.500        &      -10.960    &       22.429     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Grass]}    &       3.3275  &        5.496     &     0.605  &         0.545        &       -7.481    &       14.136     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ground]}   &       9.5118  &        7.076     &     1.344  &         0.180        &       -4.404    &       23.428     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ice]}      &      -0.9313  &        7.717     &    -0.121  &         0.904        &      -16.108    &       14.246     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Normal]}   &      18.4816  &        5.312     &     3.479  &         0.001        &        8.034    &       28.929     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Poison]}   &       8.3411  &        7.735     &     1.078  &         0.282        &       -6.871    &       23.554     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Psychic]}  &       1.8061  &        6.164     &     0.293  &         0.770        &      -10.317    &       13.930     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Rock]}     &      -3.8558  &        6.503     &    -0.593  &         0.554        &      -16.645    &        8.933     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Steel]}    &      -4.0053  &        8.044     &    -0.498  &         0.619        &      -19.826    &       11.816     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Water]}    &       9.7988  &        5.166     &     1.897  &         0.059        &       -0.361    &       19.959     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dark]}     &       5.8719  &       15.185     &     0.387  &         0.699        &      -23.993    &       35.737     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dragon]}   &      13.2777  &       14.895     &     0.891  &         0.373        &      -16.016    &       42.571     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Electric]} &      14.3228  &       17.314     &     0.827  &         0.409        &      -19.728    &       48.374     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fairy]}    &       2.8426  &       14.268     &     0.199  &         0.842        &      -25.218    &       30.903     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fighting]} &       1.9741  &       14.089     &     0.140  &         0.889        &      -25.735    &       29.683     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fire]}     &       0.2001  &       15.730     &     0.013  &         0.990        &      -30.736    &       31.136     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Flying]}   &       6.7292  &       13.581     &     0.495  &         0.621        &      -19.980    &       33.438     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ghost]}    &     -10.9402  &       15.895     &    -0.688  &         0.492        &      -42.201    &       20.321     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Grass]}    &       2.5119  &       14.540     &     0.173  &         0.863        &      -26.084    &       31.108     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ground]}   &      13.6042  &       13.655     &     0.996  &         0.320        &      -13.250    &       40.459     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ice]}      &      19.7950  &       15.068     &     1.314  &         0.190        &       -9.840    &       49.430     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.None]}     &       7.6068  &       13.162     &     0.578  &         0.564        &      -18.279    &       33.493     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Normal]}   &      17.3191  &       17.764     &     0.975  &         0.330        &      -17.618    &       52.256     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Poison]}   &       0.7770  &       14.575     &     0.053  &         0.958        &      -27.887    &       29.441     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Psychic]}  &       4.2480  &       14.174     &     0.300  &         0.765        &      -23.628    &       32.124     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Rock]}     &       6.8858  &       16.221     &     0.424  &         0.671        &      -25.017    &       38.788     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Steel]}    &     -11.9623  &       14.973     &    -0.799  &         0.425        &      -41.409    &       17.485     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Water]}    &       5.8097  &       14.763     &     0.394  &         0.694        &      -23.225    &       34.845     \\\\\n",
       "\\textbf{Attack}                     &       0.2508  &        0.051     &     4.940  &         0.000        &        0.151    &        0.351     \\\\\n",
       "\\textbf{Defense}                    &      -0.0096  &        0.060     &    -0.160  &         0.873        &       -0.127    &        0.108     \\\\\n",
       "\\textbf{Speed}                      &      -0.1538  &        0.051     &    -2.998  &         0.003        &       -0.255    &       -0.053     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}               &       0.3484  &        0.059     &     5.936  &         0.000        &        0.233    &        0.464     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}               &       0.1298  &        0.051     &     2.525  &         0.012        &        0.029    &        0.231     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 286.476 & \\textbf{  Durbin-Watson:     } &    1.917  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5187.327  \\\\\n",
       "\\textbf{Skew:}          &   2.807 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  19.725 & \\textbf{  Cond. No.          } & 9.21e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 9.21e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.392\n",
       "Model:                            OLS   Adj. R-squared:                  0.313\n",
       "Method:                 Least Squares   F-statistic:                     4.948\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           9.48e-19\n",
       "Time:                        21:06:53   Log-Likelihood:                -1765.0\n",
       "No. Observations:                 400   AIC:                             3624.\n",
       "Df Residuals:                     353   BIC:                             3812.\n",
       "Df Model:                          46                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                     10.1046     14.957      0.676      0.500     -19.312      39.521\n",
       "Legendary[T.True]             -3.2717      4.943     -0.662      0.508     -12.992       6.449\n",
       "C(Generation)[T.2]             9.2938      4.015      2.315      0.021       1.398      17.189\n",
       "C(Generation)[T.3]             2.3150      3.915      0.591      0.555      -5.385      10.015\n",
       "C(Generation)[T.4]             4.8353      4.149      1.165      0.245      -3.325      12.995\n",
       "C(Generation)[T.5]            11.4838      3.960      2.900      0.004       3.696      19.272\n",
       "C(Generation)[T.6]             4.9206      4.746      1.037      0.300      -4.413      14.254\n",
       "C(Q(\"Type 1\"))[T.Dark]        -1.4155      6.936     -0.204      0.838     -15.057      12.226\n",
       "C(Q(\"Type 1\"))[T.Dragon]       0.8509      6.900      0.123      0.902     -12.720      14.422\n",
       "C(Q(\"Type 1\"))[T.Electric]    -6.3641      6.537     -0.974      0.331     -19.220       6.491\n",
       "C(Q(\"Type 1\"))[T.Fairy]       -1.9486     10.124     -0.192      0.847     -21.859      17.962\n",
       "C(Q(\"Type 1\"))[T.Fighting]     7.0308      7.432      0.946      0.345      -7.586      21.648\n",
       "C(Q(\"Type 1\"))[T.Fire]         3.0779      6.677      0.461      0.645     -10.055      16.210\n",
       "C(Q(\"Type 1\"))[T.Flying]      -2.1231     22.322     -0.095      0.924     -46.025      41.779\n",
       "C(Q(\"Type 1\"))[T.Ghost]        5.7343      8.488      0.676      0.500     -10.960      22.429\n",
       "C(Q(\"Type 1\"))[T.Grass]        3.3275      5.496      0.605      0.545      -7.481      14.136\n",
       "C(Q(\"Type 1\"))[T.Ground]       9.5118      7.076      1.344      0.180      -4.404      23.428\n",
       "C(Q(\"Type 1\"))[T.Ice]         -0.9313      7.717     -0.121      0.904     -16.108      14.246\n",
       "C(Q(\"Type 1\"))[T.Normal]      18.4816      5.312      3.479      0.001       8.034      28.929\n",
       "C(Q(\"Type 1\"))[T.Poison]       8.3411      7.735      1.078      0.282      -6.871      23.554\n",
       "C(Q(\"Type 1\"))[T.Psychic]      1.8061      6.164      0.293      0.770     -10.317      13.930\n",
       "C(Q(\"Type 1\"))[T.Rock]        -3.8558      6.503     -0.593      0.554     -16.645       8.933\n",
       "C(Q(\"Type 1\"))[T.Steel]       -4.0053      8.044     -0.498      0.619     -19.826      11.816\n",
       "C(Q(\"Type 1\"))[T.Water]        9.7988      5.166      1.897      0.059      -0.361      19.959\n",
       "C(Q(\"Type 2\"))[T.Dark]         5.8719     15.185      0.387      0.699     -23.993      35.737\n",
       "C(Q(\"Type 2\"))[T.Dragon]      13.2777     14.895      0.891      0.373     -16.016      42.571\n",
       "C(Q(\"Type 2\"))[T.Electric]    14.3228     17.314      0.827      0.409     -19.728      48.374\n",
       "C(Q(\"Type 2\"))[T.Fairy]        2.8426     14.268      0.199      0.842     -25.218      30.903\n",
       "C(Q(\"Type 2\"))[T.Fighting]     1.9741     14.089      0.140      0.889     -25.735      29.683\n",
       "C(Q(\"Type 2\"))[T.Fire]         0.2001     15.730      0.013      0.990     -30.736      31.136\n",
       "C(Q(\"Type 2\"))[T.Flying]       6.7292     13.581      0.495      0.621     -19.980      33.438\n",
       "C(Q(\"Type 2\"))[T.Ghost]      -10.9402     15.895     -0.688      0.492     -42.201      20.321\n",
       "C(Q(\"Type 2\"))[T.Grass]        2.5119     14.540      0.173      0.863     -26.084      31.108\n",
       "C(Q(\"Type 2\"))[T.Ground]      13.6042     13.655      0.996      0.320     -13.250      40.459\n",
       "C(Q(\"Type 2\"))[T.Ice]         19.7950     15.068      1.314      0.190      -9.840      49.430\n",
       "C(Q(\"Type 2\"))[T.None]         7.6068     13.162      0.578      0.564     -18.279      33.493\n",
       "C(Q(\"Type 2\"))[T.Normal]      17.3191     17.764      0.975      0.330     -17.618      52.256\n",
       "C(Q(\"Type 2\"))[T.Poison]       0.7770     14.575      0.053      0.958     -27.887      29.441\n",
       "C(Q(\"Type 2\"))[T.Psychic]      4.2480     14.174      0.300      0.765     -23.628      32.124\n",
       "C(Q(\"Type 2\"))[T.Rock]         6.8858     16.221      0.424      0.671     -25.017      38.788\n",
       "C(Q(\"Type 2\"))[T.Steel]      -11.9623     14.973     -0.799      0.425     -41.409      17.485\n",
       "C(Q(\"Type 2\"))[T.Water]        5.8097     14.763      0.394      0.694     -23.225      34.845\n",
       "Attack                         0.2508      0.051      4.940      0.000       0.151       0.351\n",
       "Defense                       -0.0096      0.060     -0.160      0.873      -0.127       0.108\n",
       "Speed                         -0.1538      0.051     -2.998      0.003      -0.255      -0.053\n",
       "Q(\"Sp. Def\")                   0.3484      0.059      5.936      0.000       0.233       0.464\n",
       "Q(\"Sp. Atk\")                   0.1298      0.051      2.525      0.012       0.029       0.231\n",
       "==============================================================================\n",
       "Omnibus:                      286.476   Durbin-Watson:                   1.917\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5187.327\n",
       "Skew:                           2.807   Prob(JB):                         0.00\n",
       "Kurtosis:                      19.725   Cond. No.                     9.21e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.21e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model5_linear_form = 'HP ~ Attack + Defense + Speed + Legendary'\n",
    "model5_linear_form += ' + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "model5_linear_form += ' + C(Generation) + C(Q(\"Type 1\")) + C(Q(\"Type 2\"))'\n",
    "\n",
    "model5_spec = smf.ols(formula=model5_linear_form, data=pokeaman_train)\n",
    "model5_fit = model5_spec.fit()\n",
    "model5_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "742299bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3920134083531893\n",
      "'Out of sample' R-squared: 0.30015614488652215\n"
     ]
    }
   ],
   "source": [
    "yhat_model5 = model5_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model5_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model5)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6dea816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   24.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>2.25e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:06:53</td>     <th>  Log-Likelihood:    </th> <td> -1783.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3585.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   391</td>      <th>  BIC:               </th> <td>   3621.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                          <td>   22.8587</td> <td>    3.876</td> <td>    5.897</td> <td> 0.000</td> <td>   15.238</td> <td>   30.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th> <td>   17.5594</td> <td>    3.339</td> <td>    5.258</td> <td> 0.000</td> <td>   10.994</td> <td>   24.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>  <td>    9.0301</td> <td>    3.172</td> <td>    2.847</td> <td> 0.005</td> <td>    2.794</td> <td>   15.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>         <td>    6.5293</td> <td>    2.949</td> <td>    2.214</td> <td> 0.027</td> <td>    0.732</td> <td>   12.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>         <td>    8.4406</td> <td>    2.711</td> <td>    3.114</td> <td> 0.002</td> <td>    3.112</td> <td>   13.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                             <td>    0.2454</td> <td>    0.037</td> <td>    6.639</td> <td> 0.000</td> <td>    0.173</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                              <td>   -0.1370</td> <td>    0.045</td> <td>   -3.028</td> <td> 0.003</td> <td>   -0.226</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                       <td>    0.3002</td> <td>    0.045</td> <td>    6.662</td> <td> 0.000</td> <td>    0.212</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                       <td>    0.1192</td> <td>    0.042</td> <td>    2.828</td> <td> 0.005</td> <td>    0.036</td> <td>    0.202</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>271.290</td> <th>  Durbin-Watson:     </th> <td>   1.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4238.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.651</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>18.040</td>  <th>  Cond. No.          </th> <td>    618.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                     &        HP        & \\textbf{  R-squared:         } &     0.333   \\\\\n",
       "\\textbf{Model:}                             &       OLS        & \\textbf{  Adj. R-squared:    } &     0.319   \\\\\n",
       "\\textbf{Method:}                            &  Least Squares   & \\textbf{  F-statistic:       } &     24.36   \\\\\n",
       "\\textbf{Date:}                              & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  2.25e-30   \\\\\n",
       "\\textbf{Time:}                              &     21:06:53     & \\textbf{  Log-Likelihood:    } &   -1783.6   \\\\\n",
       "\\textbf{No. Observations:}                  &         400      & \\textbf{  AIC:               } &     3585.   \\\\\n",
       "\\textbf{Df Residuals:}                      &         391      & \\textbf{  BIC:               } &     3621.   \\\\\n",
       "\\textbf{Df Model:}                          &           8      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                   &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                          &      22.8587  &        3.876     &     5.897  &         0.000        &       15.238    &       30.479     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]} &      17.5594  &        3.339     &     5.258  &         0.000        &       10.994    &       24.125     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}  &       9.0301  &        3.172     &     2.847  &         0.005        &        2.794    &       15.266     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}         &       6.5293  &        2.949     &     2.214  &         0.027        &        0.732    &       12.327     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}         &       8.4406  &        2.711     &     3.114  &         0.002        &        3.112    &       13.770     \\\\\n",
       "\\textbf{Attack}                             &       0.2454  &        0.037     &     6.639  &         0.000        &        0.173    &        0.318     \\\\\n",
       "\\textbf{Speed}                              &      -0.1370  &        0.045     &    -3.028  &         0.003        &       -0.226    &       -0.048     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                       &       0.3002  &        0.045     &     6.662  &         0.000        &        0.212    &        0.389     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                       &       0.1192  &        0.042     &     2.828  &         0.005        &        0.036    &        0.202     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 271.290 & \\textbf{  Durbin-Watson:     } &    1.999  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 4238.692  \\\\\n",
       "\\textbf{Skew:}          &   2.651 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  18.040 & \\textbf{  Cond. No.          } &     618.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.333\n",
       "Model:                            OLS   Adj. R-squared:                  0.319\n",
       "Method:                 Least Squares   F-statistic:                     24.36\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           2.25e-30\n",
       "Time:                        21:06:53   Log-Likelihood:                -1783.6\n",
       "No. Observations:                 400   AIC:                             3585.\n",
       "Df Residuals:                     391   BIC:                             3621.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================================\n",
       "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------\n",
       "Intercept                             22.8587      3.876      5.897      0.000      15.238      30.479\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]    17.5594      3.339      5.258      0.000      10.994      24.125\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]      9.0301      3.172      2.847      0.005       2.794      15.266\n",
       "I(Generation == 2)[T.True]             6.5293      2.949      2.214      0.027       0.732      12.327\n",
       "I(Generation == 5)[T.True]             8.4406      2.711      3.114      0.002       3.112      13.770\n",
       "Attack                                 0.2454      0.037      6.639      0.000       0.173       0.318\n",
       "Speed                                 -0.1370      0.045     -3.028      0.003      -0.226      -0.048\n",
       "Q(\"Sp. Def\")                           0.3002      0.045      6.662      0.000       0.212       0.389\n",
       "Q(\"Sp. Atk\")                           0.1192      0.042      2.828      0.005       0.036       0.202\n",
       "==============================================================================\n",
       "Omnibus:                      271.290   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4238.692\n",
       "Skew:                           2.651   Prob(JB):                         0.00\n",
       "Kurtosis:                      18.040   Cond. No.                         618.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model6_linear_form = 'HP ~ Attack + Speed + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "# And here we'll add the significant indicators from the previous model\n",
    "# https://chatgpt.com/share/81ab88df-4f07-49f9-a44a-de0cfd89c67c\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model6_linear_form += ' + I(Generation==2)'\n",
    "model6_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model6_spec = smf.ols(formula=model6_linear_form, data=pokeaman_train)\n",
    "model6_fit = model6_spec.fit()\n",
    "model6_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c19098d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908\n",
      "'Out of sample' R-squared: 0.29572460427079933\n"
     ]
    }
   ],
   "source": [
    "yhat_model6 = model6_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38264183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.20e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:06:53</td>     <th>  Log-Likelihood:    </th> <td> -1769.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3579.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   380</td>      <th>  BIC:               </th> <td>   3659.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                     <td></td>                       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                              <td>   95.1698</td> <td>   34.781</td> <td>    2.736</td> <td> 0.007</td> <td>   26.783</td> <td>  163.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th>     <td>   18.3653</td> <td>    3.373</td> <td>    5.445</td> <td> 0.000</td> <td>   11.733</td> <td>   24.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>      <td>    9.2913</td> <td>    3.140</td> <td>    2.959</td> <td> 0.003</td> <td>    3.117</td> <td>   15.466</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>             <td>    7.0711</td> <td>    2.950</td> <td>    2.397</td> <td> 0.017</td> <td>    1.271</td> <td>   12.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>             <td>    7.8557</td> <td>    2.687</td> <td>    2.923</td> <td> 0.004</td> <td>    2.572</td> <td>   13.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                 <td>   -0.6975</td> <td>    0.458</td> <td>   -1.523</td> <td> 0.129</td> <td>   -1.598</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                  <td>   -1.8147</td> <td>    0.554</td> <td>   -3.274</td> <td> 0.001</td> <td>   -2.905</td> <td>   -0.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                           <td>    0.0189</td> <td>    0.007</td> <td>    2.882</td> <td> 0.004</td> <td>    0.006</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                           <td>   -0.5532</td> <td>    0.546</td> <td>   -1.013</td> <td> 0.312</td> <td>   -1.627</td> <td>    0.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                    <td>    0.0090</td> <td>    0.007</td> <td>    1.311</td> <td> 0.191</td> <td>   -0.004</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                     <td>    0.0208</td> <td>    0.008</td> <td>    2.571</td> <td> 0.011</td> <td>    0.005</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>              <td>   -0.0002</td> <td> 9.06e-05</td> <td>   -2.277</td> <td> 0.023</td> <td>   -0.000</td> <td>-2.82e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                           <td>   -0.7277</td> <td>    0.506</td> <td>   -1.439</td> <td> 0.151</td> <td>   -1.722</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                    <td>    0.0136</td> <td>    0.005</td> <td>    2.682</td> <td> 0.008</td> <td>    0.004</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                     <td>    0.0146</td> <td>    0.007</td> <td>    2.139</td> <td> 0.033</td> <td>    0.001</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>              <td>   -0.0002</td> <td>  5.4e-05</td> <td>   -3.383</td> <td> 0.001</td> <td>   -0.000</td> <td>-7.65e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0103</td> <td>    0.007</td> <td>    1.516</td> <td> 0.130</td> <td>   -0.003</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>   -0.0001</td> <td> 6.71e-05</td> <td>   -2.119</td> <td> 0.035</td> <td>   -0.000</td> <td>-1.03e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0002</td> <td> 8.82e-05</td> <td>   -2.075</td> <td> 0.039</td> <td>   -0.000</td> <td>-9.62e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>  2.03e-06</td> <td> 7.42e-07</td> <td>    2.734</td> <td> 0.007</td> <td>  5.7e-07</td> <td> 3.49e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.34e+09. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                         &        HP        & \\textbf{  R-squared:         } &     0.378   \\\\\n",
       "\\textbf{Model:}                                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.347   \\\\\n",
       "\\textbf{Method:}                                &  Least Squares   & \\textbf{  F-statistic:       } &     12.16   \\\\\n",
       "\\textbf{Date:}                                  & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.20e-29   \\\\\n",
       "\\textbf{Time:}                                  &     21:06:53     & \\textbf{  Log-Likelihood:    } &   -1769.5   \\\\\n",
       "\\textbf{No. Observations:}                      &         400      & \\textbf{  AIC:               } &     3579.   \\\\\n",
       "\\textbf{Df Residuals:}                          &         380      & \\textbf{  BIC:               } &     3659.   \\\\\n",
       "\\textbf{Df Model:}                              &          19      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                              &      95.1698  &       34.781     &     2.736  &         0.007        &       26.783    &      163.556     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]}     &      18.3653  &        3.373     &     5.445  &         0.000        &       11.733    &       24.997     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}      &       9.2913  &        3.140     &     2.959  &         0.003        &        3.117    &       15.466     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}             &       7.0711  &        2.950     &     2.397  &         0.017        &        1.271    &       12.871     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}             &       7.8557  &        2.687     &     2.923  &         0.004        &        2.572    &       13.140     \\\\\n",
       "\\textbf{Attack}                                 &      -0.6975  &        0.458     &    -1.523  &         0.129        &       -1.598    &        0.203     \\\\\n",
       "\\textbf{Speed}                                  &      -1.8147  &        0.554     &    -3.274  &         0.001        &       -2.905    &       -0.725     \\\\\n",
       "\\textbf{Attack:Speed}                           &       0.0189  &        0.007     &     2.882  &         0.004        &        0.006    &        0.032     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                           &      -0.5532  &        0.546     &    -1.013  &         0.312        &       -1.627    &        0.521     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                    &       0.0090  &        0.007     &     1.311  &         0.191        &       -0.004    &        0.023     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                     &       0.0208  &        0.008     &     2.571  &         0.011        &        0.005    &        0.037     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}              &      -0.0002  &     9.06e-05     &    -2.277  &         0.023        &       -0.000    &    -2.82e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                           &      -0.7277  &        0.506     &    -1.439  &         0.151        &       -1.722    &        0.267     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                    &       0.0136  &        0.005     &     2.682  &         0.008        &        0.004    &        0.024     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                     &       0.0146  &        0.007     &     2.139  &         0.033        &        0.001    &        0.028     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}              &      -0.0002  &      5.4e-05     &    -3.383  &         0.001        &       -0.000    &    -7.65e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0103  &        0.007     &     1.516  &         0.130        &       -0.003    &        0.024     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &      -0.0001  &     6.71e-05     &    -2.119  &         0.035        &       -0.000    &    -1.03e-05     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0002  &     8.82e-05     &    -2.075  &         0.039        &       -0.000    &    -9.62e-06     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &     2.03e-06  &     7.42e-07     &     2.734  &         0.007        &      5.7e-07    &     3.49e-06     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.34e+09. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.378\n",
       "Model:                            OLS   Adj. R-squared:                  0.347\n",
       "Method:                 Least Squares   F-statistic:                     12.16\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           4.20e-29\n",
       "Time:                        21:06:53   Log-Likelihood:                -1769.5\n",
       "No. Observations:                 400   AIC:                             3579.\n",
       "Df Residuals:                     380   BIC:                             3659.\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================================\n",
       "                                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------------\n",
       "Intercept                                 95.1698     34.781      2.736      0.007      26.783     163.556\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]        18.3653      3.373      5.445      0.000      11.733      24.997\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]          9.2913      3.140      2.959      0.003       3.117      15.466\n",
       "I(Generation == 2)[T.True]                 7.0711      2.950      2.397      0.017       1.271      12.871\n",
       "I(Generation == 5)[T.True]                 7.8557      2.687      2.923      0.004       2.572      13.140\n",
       "Attack                                    -0.6975      0.458     -1.523      0.129      -1.598       0.203\n",
       "Speed                                     -1.8147      0.554     -3.274      0.001      -2.905      -0.725\n",
       "Attack:Speed                               0.0189      0.007      2.882      0.004       0.006       0.032\n",
       "Q(\"Sp. Def\")                              -0.5532      0.546     -1.013      0.312      -1.627       0.521\n",
       "Attack:Q(\"Sp. Def\")                        0.0090      0.007      1.311      0.191      -0.004       0.023\n",
       "Speed:Q(\"Sp. Def\")                         0.0208      0.008      2.571      0.011       0.005       0.037\n",
       "Attack:Speed:Q(\"Sp. Def\")                 -0.0002   9.06e-05     -2.277      0.023      -0.000   -2.82e-05\n",
       "Q(\"Sp. Atk\")                              -0.7277      0.506     -1.439      0.151      -1.722       0.267\n",
       "Attack:Q(\"Sp. Atk\")                        0.0136      0.005      2.682      0.008       0.004       0.024\n",
       "Speed:Q(\"Sp. Atk\")                         0.0146      0.007      2.139      0.033       0.001       0.028\n",
       "Attack:Speed:Q(\"Sp. Atk\")                 -0.0002    5.4e-05     -3.383      0.001      -0.000   -7.65e-05\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0103      0.007      1.516      0.130      -0.003       0.024\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          -0.0001   6.71e-05     -2.119      0.035      -0.000   -1.03e-05\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0002   8.82e-05     -2.075      0.039      -0.000   -9.62e-06\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")   2.03e-06   7.42e-07      2.734      0.007     5.7e-07    3.49e-06\n",
       "==============================================================================\n",
       "Omnibus:                      252.300   Durbin-Watson:                   1.953\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3474.611\n",
       "Skew:                           2.438   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.590   Cond. No.                     2.34e+09\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.34e+09. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's a slight change that seems to perhaps improve prediction...\n",
    "model7_linear_form = 'HP ~ Attack * Speed * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form += ' + I(Generation==2)'\n",
    "model7_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model7_spec = smf.ols(formula=model7_linear_form, data=pokeaman_train)\n",
    "model7_fit = model7_spec.fit()\n",
    "model7_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8493ab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456\n",
      "'Out of sample' R-squared: 0.35055389205977444\n"
     ]
    }
   ],
   "source": [
    "yhat_model7 = model7_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91464b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>    15.4</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } &     15.4  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's a slight change that seems to perhas improve prediction...\n",
    "model7_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Speed))'\n",
    "model7_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# We DO NOT center and scale indicator variables\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form_CS += ' + I(Generation==2)'\n",
    "model7_linear_form_CS += ' + I(Generation==5)'\n",
    "\n",
    "model7_CS_spec = smf.ols(formula=model7_linear_form_CS, data=pokeaman_train)\n",
    "model7_CS_fit = model7_CS_spec.fit()\n",
    "model7_CS_fit.summary().tables[-1] \n",
    "# \"Cond. No.\" is NOW 15.4 due to centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca971edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Cond. No.\" WAS 2,340,000,000 WITHOUT to centering and scaling\n",
    "model7_fit.summary().tables[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a83ced",
   "metadata": {},
   "source": [
    "1. **Model 5 Development** (from Models 3 & 4):\n",
    "- Strikes a balance between Models 3 (too simple) and 4 (too complex)\n",
    "- Includes all main predictors without interactions: Attack, Defense, Speed, Legendary, Sp. Def, Sp. Atk\n",
    "- Adds categorical variables: Generation, Type 1, Type 2\n",
    "- Performance:\n",
    "  - Training R² = 0.392\n",
    "  - Testing R² = 0.300\n",
    "  - Less overfitting than Model 4 but still complex\n",
    "\n",
    "2. **Model 6 Development** (from Model 5):\n",
    "- Simplifies Model 5 by keeping only statistically significant predictors\n",
    "- Retains: Attack, Speed, Sp. Def, Sp. Atk\n",
    "- Keeps only significant categorical indicators:\n",
    "  - Type 1 = \"Normal\"\n",
    "  - Type 1 = \"Water\"\n",
    "  - Generation = 2\n",
    "  - Generation = 5\n",
    "- Performance:\n",
    "  - Training R² = 0.333\n",
    "  - Testing R² = 0.296\n",
    "  - More stable, similar training/testing performance\n",
    "\n",
    "3. **Model 7 Development** (from Model 6):\n",
    "- Keeps Model 6's significant categorical indicators\n",
    "- Adds interactions between continuous variables:\n",
    "  - Attack * Speed * Sp. Def * Sp. Atk\n",
    "- Performance:\n",
    "  - Training R² = 0.378\n",
    "  - Testing R² = 0.351\n",
    "  - Shows improved predictive power while maintaining generalization\n",
    "\n",
    "The progression shows systematic model building:\n",
    "1. Start with comprehensive model (Model 5)\n",
    "2. Select significant predictors (Model 6)\n",
    "3. Add strategic interactions while maintaining stability (Model 7)\n",
    "\n",
    "Model 7 achieves the best balance between complexity and predictive power, with good generalization (similar training and test performance) and a much better condition number after centering/scaling (15.4 vs 2.34e+09)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79101d6",
   "metadata": {},
   "source": [
    "### 8. Work with a ChatBot to write a *for* loop to create, collect, and visualize many different paired \"in sample\" and \"out of sample\" *model performance* metric actualizations (by not using *np.random.seed(130)* within each loop iteration); and explain in your own words the meaning of your results and purpose of this demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18453e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Number of iterations\n",
    "reps = 100\n",
    "\n",
    "# Initialize arrays to store R-squared values\n",
    "in_sample_r2 = np.zeros(reps)\n",
    "out_of_sample_r2 = np.zeros(reps)\n",
    "\n",
    "# Define the model formula (using Model 3 as example)\n",
    "formula = 'HP ~ Attack + Defense'\n",
    "\n",
    "# Run the loop\n",
    "for i in range(reps):\n",
    "    # Split data without fixed seed\n",
    "    train_data, test_data = train_test_split(pokeaman, train_size=0.5)\n",
    "    \n",
    "    # Fit model\n",
    "    model = smf.ols(formula=formula, data=train_data).fit()\n",
    "    \n",
    "    # Calculate R-squared values\n",
    "    in_sample_r2[i] = model.rsquared\n",
    "    \n",
    "    # Calculate out-of-sample R-squared\n",
    "    y_test = test_data.HP\n",
    "    y_pred = model.predict(test_data)\n",
    "    out_of_sample_r2[i] = np.corrcoef(y_test, y_pred)[0,1]**2\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "results_df = pd.DataFrame({\n",
    "    'In-Sample R²': in_sample_r2,\n",
    "    'Out-of-Sample R²': out_of_sample_r2\n",
    "})\n",
    "\n",
    "# Create scatter plot\n",
    "fig = px.scatter(results_df, \n",
    "                 x='In-Sample R²', \n",
    "                 y='Out-of-Sample R²',\n",
    "                 title='Model Performance Across Different Data Splits')\n",
    "\n",
    "# Add y=x reference line\n",
    "fig.add_scatter(x=[0, max(max(in_sample_r2), max(out_of_sample_r2))],\n",
    "                y=[0, max(max(in_sample_r2), max(out_of_sample_r2))],\n",
    "                mode='lines',\n",
    "                name='y=x line',\n",
    "                line=dict(dash='dash'))\n",
    "\n",
    "fig.show(renderer=\"png\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(f\"Mean In-Sample R²: {np.mean(in_sample_r2):.3f} (±{np.std(in_sample_r2):.3f})\")\n",
    "print(f\"Mean Out-of-Sample R²: {np.mean(out_of_sample_r2):.3f} (±{np.std(out_of_sample_r2):.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd03689",
   "metadata": {},
   "source": [
    "1. **In-Sample Performance**:\n",
    "- Mean R² = 0.198 (19.8%)\n",
    "- Standard Deviation = ±0.053 (5.3%)\n",
    "- This means that on training data, the model typically explains about 20% of the variance in HP values\n",
    "- The performance varies between approximately 14.5% to 25.1% (mean ± 1 standard deviation)\n",
    "\n",
    "2. **Out-of-Sample Performance**:\n",
    "- Mean R² = 0.178 (17.8%)\n",
    "- Standard Deviation = ±0.052 (5.2%)\n",
    "- On test data, the model explains about 18% of the variance\n",
    "- Performance typically ranges from 12.6% to 23% \n",
    "\n",
    "3. **Key Insights**:\n",
    "- The difference between in-sample (19.8%) and out-of-sample (17.8%) is small (~2%)\n",
    "- Similar standard deviations (5.3% vs 5.2%) indicate consistent variability\n",
    "- This suggests the model is:\n",
    "  - Not overfitting (small gap between training and testing)\n",
    "  - Stable (similar standard deviations)\n",
    "  - Consistently mediocre (explaining only about 15-25% of variance)\n",
    "\n",
    "4. **Practical Implications**:\n",
    "- The model's performance is consistent but modest\n",
    "- Users can expect around 18% R² on new data, give or take about 5%\n",
    "- The small gap between training and testing suggests reliability, even if the overall performance isn't stellar\n",
    "\n",
    "This analysis gives us much more confidence about the model's typical behavior than a single train-test split would provide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8bd4e5",
   "metadata": {},
   "source": [
    "### 9. Work with a ChatBot to understand the meaning of the illustration below; and, explain this in your own words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea91cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7_gen1_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model7_gen1_predict_future_fit = model7_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model7_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aa9dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7_gen1to5_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model7_gen1to5_predict_future_fit = model7_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model7_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ceab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6_gen1_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model6_gen1_predict_future_fit = model6_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model6_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fe9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6_gen1to5_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model6_gen1to5_predict_future_fit = model6_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model6_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fa4c8f",
   "metadata": {},
   "source": [
    "1. **Model 7 Performance (Complex Model)**:\n",
    "\n",
    "Original Random Split:\n",
    "- Training R² = 0.378\n",
    "- Testing R² = 0.351\n",
    "- Shows good generalization in random splitting\n",
    "\n",
    "Generation 1 → Future Generations:\n",
    "- Training R² (Gen 1) = 0.573\n",
    "- Testing R² (Gen 2-6) = 0.112\n",
    "- Severe drop in performance when predicting future generations\n",
    "\n",
    "Generations 1-5 → Generation 6:\n",
    "- Training R² (Gen 1-5) = 0.390\n",
    "- Testing R² (Gen 6) = 0.234\n",
    "- Still shows significant performance drop\n",
    "\n",
    "2. **Model 6 Performance (Simpler Model)**:\n",
    "\n",
    "Original Random Split:\n",
    "- Training R² = 0.333\n",
    "- Testing R² = 0.296\n",
    "- Good generalization in random splitting\n",
    "\n",
    "Generation 1 → Future Generations:\n",
    "- Training R² (Gen 1) = 0.443\n",
    "- Testing R² (Gen 2-6) = 0.193\n",
    "- Performance drops but less severely than Model 7\n",
    "\n",
    "Generations 1-5 → Generation 6:\n",
    "- Training R² (Gen 1-5) = 0.335\n",
    "- Testing R² (Gen 6) = 0.263\n",
    "- Most stable performance across generations\n",
    "\n",
    "3. **Key Insights**:\n",
    "\n",
    "a) **Time-Based Testing is More Realistic**:\n",
    "- Random splits don't reflect real-world usage where models predict future data\n",
    "- Both models perform worse in chronological testing than random splitting\n",
    "\n",
    "b) **Simpler Model (6) is More Robust**:\n",
    "- Shows smaller performance drops in chronological testing\n",
    "- More consistent performance across generations\n",
    "- Better suited for real-world predictions\n",
    "\n",
    "c) **Model Complexity Trade-off**:\n",
    "- Complex Model 7 shows higher variance in performance\n",
    "- Simpler Model 6 shows more stable, reliable predictions\n",
    "- Demonstrates why simpler models might be preferred even with slightly lower overall performance\n",
    "\n",
    "This analysis reveals that evaluating models on random splits can be misleading - real-world performance on future data may be significantly different. The simpler Model 6 proves more reliable for actual predictive use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db767e",
   "metadata": {},
   "source": [
    "### ChatBot Summary \n",
    "I did not use chatgpt and the bot I used does not allow for links to share the chat. Here is the chat summary:\n",
    "\n",
    "Here's a summary of the key concepts we covered through these questions:\n",
    "\n",
    "1. **Model Evaluation and Splitting (Q5)**\n",
    "- Demonstrated the importance of train-test splits for model evaluation\n",
    "- Showed how simple models (Model 3) can generalize better than complex ones (Model 4)\n",
    "- Introduced the concept of overfitting through comparing in-sample vs out-of-sample R²\n",
    "\n",
    "2. **Multicollinearity and Design Matrix (Q6)**\n",
    "- Explored how interactions in Model 4 create new predictor variables\n",
    "- Discussed how multicollinearity affects model stability\n",
    "- Showed how centering and scaling can help diagnose multicollinearity issues\n",
    "- Demonstrated the importance of condition numbers as diagnostic tools\n",
    "\n",
    "3. **Model Building Process (Q7)**\n",
    "- Traced the evolution from complex Model 5 to balanced Model 7\n",
    "- Showed systematic approach to model selection:\n",
    "  - Start comprehensive (Model 5)\n",
    "  - Select significant predictors (Model 6)\n",
    "  - Add strategic interactions (Model 7)\n",
    "- Demonstrated importance of balancing complexity with performance\n",
    "\n",
    "4. **Performance Variability (Q8)**\n",
    "- Used repeated random splits to assess model stability\n",
    "- Showed how performance varies across different data splits\n",
    "- Demonstrated importance of looking at distributions rather than single splits\n",
    "- Provided more robust evaluation through mean and standard deviation of R²\n",
    "\n",
    "5. **Real-World Application (Q9)**\n",
    "- Tested models on chronological data (Pokemon generations)\n",
    "- Showed how random split performance differs from real-world sequential predictions\n",
    "- Demonstrated that simpler models (Model 6) can be more robust for future predictions\n",
    "- Highlighted importance of realistic evaluation methods\n",
    "\n",
    "Overall, these questions illustrated fundamental concepts in statistical modeling:\n",
    "- The trade-off between model complexity and generalization\n",
    "- The importance of proper model validation\n",
    "- The value of simpler, more interpretable models\n",
    "- The need to test models in ways that reflect their intended use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
